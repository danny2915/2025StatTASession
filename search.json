[
  {
    "objectID": "quiz/Quiz_5_Answer.html",
    "href": "quiz/Quiz_5_Answer.html",
    "title": "Quiz 5 Answers",
    "section": "",
    "text": "Open in new tab · Download PDF",
    "crumbs": [
      "Quizzes",
      "Quiz 5 Answers"
    ]
  },
  {
    "objectID": "quiz/Quiz_4_Answer.html",
    "href": "quiz/Quiz_4_Answer.html",
    "title": "Quiz 4 Answers",
    "section": "",
    "text": "Open in new tab · Download PDF",
    "crumbs": [
      "Quizzes",
      "Quiz 4 Answers"
    ]
  },
  {
    "objectID": "quiz/Quiz_3_Answer.html",
    "href": "quiz/Quiz_3_Answer.html",
    "title": "Quiz 3 Answers",
    "section": "",
    "text": "Open in new tab · Download PDF",
    "crumbs": [
      "Quizzes",
      "Quiz 3 Answers"
    ]
  },
  {
    "objectID": "quiz/Quiz_2_Answer.html",
    "href": "quiz/Quiz_2_Answer.html",
    "title": "Quiz 2 Answers",
    "section": "",
    "text": "Open in new tab · Download PDF",
    "crumbs": [
      "Quizzes",
      "Quiz 2 Answers"
    ]
  },
  {
    "objectID": "quiz/Quiz_1_Answer.html",
    "href": "quiz/Quiz_1_Answer.html",
    "title": "Quiz 1 Answers",
    "section": "",
    "text": "Open in new tab · Download PDF",
    "crumbs": [
      "Quizzes",
      "Quiz 1 Answers"
    ]
  },
  {
    "objectID": "homework/hw6_answer.html",
    "href": "homework/hw6_answer.html",
    "title": "Homework 6 Answers",
    "section": "",
    "text": "If you find any typos or errors, please feel free to contact me via email at r13323002@ntu.edu.tw. I would appreciate it and will correct the solution to prevent any misunderstandings.\nFor some R commands marked with ‘OPTIONAL,’ you don’t need to learn them. You will be completely fine on the computer quiz even if you choose to ignore them.\nIf you’re having trouble understanding the code, don’t hesitate to ask me for help. I’ll do my best to assist you during office hours or after the TA session.",
    "crumbs": [
      "Homework Solutions",
      "Homework 6 Answers"
    ]
  },
  {
    "objectID": "homework/hw6_answer.html#computer-exercises",
    "href": "homework/hw6_answer.html#computer-exercises",
    "title": "Homework 6 Answers",
    "section": "1 Computer Exercises",
    "text": "1 Computer Exercises\n\n1.1 Correlation Coefficient\n\n# correlation between x1 and y1\ncor(xydata$x1, xydata$y1)\n\n[1] 0.8164205\n\n\n\n# correlation between x2 and y2\ncor(xydata$x2, xydata$y2)\n\n[1] 0.8162365\n\n\n\n# correlation between x3 and y3\ncor(xydata$x3, xydata$y3)\n\n[1] 0.8162867\n\n\n\n# correlation between x4 and y4\ncor(xydata$x4, xydata$y4)\n\n[1] 0.8165214\n\n\n\n\n1.2 Least Squares Regression\n\nfit1 &lt;- lm(xydata$y1 ~ xydata$x1)\nsummary(fit1)\n\n\nCall:\nlm(formula = xydata$y1 ~ xydata$x1)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.92127 -0.45577 -0.04136  0.70941  1.83882 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   3.0001     1.1247   2.667  0.02573 * \nxydata$x1     0.5001     0.1179   4.241  0.00217 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.237 on 9 degrees of freedom\nMultiple R-squared:  0.6665,    Adjusted R-squared:  0.6295 \nF-statistic: 17.99 on 1 and 9 DF,  p-value: 0.00217\n\n\n\nfit2 &lt;- lm(xydata$y2 ~ xydata$x2)\nsummary(fit2)\n\n\nCall:\nlm(formula = xydata$y2 ~ xydata$x2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.9009 -0.7609  0.1291  0.9491  1.2691 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)    3.001      1.125   2.667  0.02576 * \nxydata$x2      0.500      0.118   4.239  0.00218 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.237 on 9 degrees of freedom\nMultiple R-squared:  0.6662,    Adjusted R-squared:  0.6292 \nF-statistic: 17.97 on 1 and 9 DF,  p-value: 0.002179\n\n\n\nfit3 &lt;- lm(xydata$y3 ~ xydata$x3)\nsummary(fit3)\n\n\nCall:\nlm(formula = xydata$y3 ~ xydata$x3)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.1586 -0.6146 -0.2303  0.1540  3.2411 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   3.0025     1.1245   2.670  0.02562 * \nxydata$x3     0.4997     0.1179   4.239  0.00218 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.236 on 9 degrees of freedom\nMultiple R-squared:  0.6663,    Adjusted R-squared:  0.6292 \nF-statistic: 17.97 on 1 and 9 DF,  p-value: 0.002176\n\n\n\nfit4 &lt;- lm(xydata$y4 ~ xydata$x4)\nsummary(fit4)\n\n\nCall:\nlm(formula = xydata$y4 ~ xydata$x4)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-1.751 -0.831  0.000  0.809  1.839 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   3.0017     1.1239   2.671  0.02559 * \nxydata$x4     0.4999     0.1178   4.243  0.00216 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.236 on 9 degrees of freedom\nMultiple R-squared:  0.6667,    Adjusted R-squared:  0.6297 \nF-statistic:    18 on 1 and 9 DF,  p-value: 0.002165\n\n\n\n\n1.3 Scatter Plot & Residual Plot\n\n1.3.1 Scatter Plot\nggplot(xydata, aes(x = x1, y = y1)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, col = \"red\") +\n  labs(title = \"Scatter plot of x1 and y1\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nggplot(xydata, aes(x = x2, y = y2)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, col = \"red\") +\n  labs(title = \"Scatter plot of x2 and y2\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nggplot(xydata, aes(x = x3, y = y3)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, col = \"red\") +\n  labs(title = \"Scatter plot of x3 and y3\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nggplot(xydata, aes(x = x4, y = y4)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, col = \"red\") +\n  labs(title = \"Scatter plot of x4 and y4\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\n\n\n1.3.2 Residual Plot\nggplot() +\n  geom_point(mapping = aes(x = xydata$x1, y = fit1$residuals)) +\n  labs(title = \"Scatter plot of x1 and residual\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nggplot() +\n  geom_point(mapping = aes(x = xydata$x2, y = fit2$residuals)) +\n  labs(title = \"Scatter plot of x2 and residual\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nggplot() +\n  geom_point(mapping = aes(x = xydata$x3, y = fit3$residuals)) +\n  labs(title = \"Scatter plot of x3 and residual\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nggplot() +\n  geom_point(mapping = aes(x = xydata$x4, y = fit4$residuals)) +\n  labs(title = \"Scatter plot of x4 and residual\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nFrom the scatter plot for each pair of data, we can notice that pairs \\((x_1,y_1)\\) and \\((x_3,y_3)\\) basically follows the linear trend despite an outlier in pair \\((x_3,y_3)\\). The linear model with higer-order polynomial term will be more appropriate for pair \\((x_2,y_4)\\); while pair \\((x_4,y_4)\\) doesn’t suit linear estimation.",
    "crumbs": [
      "Homework Solutions",
      "Homework 6 Answers"
    ]
  },
  {
    "objectID": "homework/hw6_answer.html#textbook-exercise",
    "href": "homework/hw6_answer.html#textbook-exercise",
    "title": "Homework 6 Answers",
    "section": "2 Textbook Exercise",
    "text": "2 Textbook Exercise\n\n2.1 Question 8.2\n\nThere is a fan shape in the residual plot. Variability around the regression line increases as \\(x\\) increases. Since there is a trend in the residual plot, the linear model method we have described would not be appropriate for these data.\nThere is an apparent curvature in the residual plot. A linear model would not be appropriate for these data.\n\n\n\n2.2 Question 8.14\n\nThe relationship is strong and positive. However, there appears to be some departure from linearity as the scatterplot shows somewhat of a fan shape. There is less variability in weights for people with lower hip girth measurements than for people with larger hip girth measurements. One explanation for the fan shape might be that the data are composed of two groups of people (males and females) who are likely to have a different relationship between their weights and hip girths.\nChanging the units, even if just for one of the variables, will not change the form, direction or strength of the relationship between the two variables.\n\n\n\n2.3 Question 8.22\n\nThere is a positive, moderate, linear association between number of calories and amount of carbohydrates. In addition, the amount of carbohydrates is more variable for menu items with higher calories, indicating non-constant variance. There also appear to be two clusters of data: a patch of about a dozen observations in the lower left and a larger patch on the right side.\nExplanatory: number of calories. Response: amount of carbohydrates (in grams).\nWith a regression line, we can predict the amount of carbohydrates for a given number of calories. This may be useful if only calorie counts for the food items are posted but the amount of carbohydrates in each food item is not readily available.\nEven though the relationship appears linear in the scatterplot, the constant variability assumption is violated. We should not fit a least squares line to these data.\n\n\n\n2.4 Question 8.26\n\n\\[\n\\widehat{\\text{headrwt}}=-0.357+4.034\\times\\text{body\\_weight}\n\\]\nExplanatory: number of calories. Response: amount of carbohydrates (in grams).\nWith a regression line, we can predict the amount of carbohydrates for a given number of calories. This may be useful if only calorie counts for the food items are posted but the amount of carbohydrates in each food item is not readily available.\nEven though the relationship appears linear in the scatterplot, the constant variability assumption is violated. We should not fit a least squares line to these data.\n\\(\\sqrt{0.6466}=0.8041\\).\n\n\n\n2.5 Question 8.32\n\nThe relationship appears to be strong, positive, and linear. There is one potential outlier: the student who had 9 cans of beer.\n\\[\n\\widehat{\\text{BAC}}=-0.0127+0.0180\\times\\text{beers}\n\\] Slope: For each additional can of beer consumed, the model predicts an additional 0.0180 grams per deciliter BAC.\nIntercept: Students who don’t have any beer are expected to have a blood alcohol content of -0.0127.\nThe hypotheses are as follows: \\[\n\\begin{cases}\nH_0: \\text{The true slope coefficient of number of beers is zero. } (\\beta_1=0)\\\\\nH_A: \\text{The true slope coefficient of number of beers is different than zero. } (\\beta_1\\neq 0)\n\\end{cases}\n\\] The p-value is approximately 0. (Note that this output doesn’t mean the p-value is exactly zero, only that when rounded to four decimal places it is zero.) With such a small p-value and since the data showed a positive relationship, we reject \\(H_0\\) and conclude that the data provide convincing evidence that number of cans of beer consumed and blood alcohol content are positively correlated and the true slope parameter is greater than 0.\n\\(R^2=0.892=0.79\\). Approximately 79% of the variability in blood alcohol content can be explained by number of cans of beer consumed.\nIt would probably be weaker. This study had people of very similar ages, and they also had identical drinks. In bars and elsewhere, drinks vary widely in the amount of alcohol they contain.\n\n\n\n2.6 Question 8.42\n\nSince \\(R^2 = r^2 = 0.72\\) and the scatterplot shows a negative trend, \\[ r = -\\sqrt{0.72} \\approx -0.85. \\]\nSlope: \\[ b_1 = r \\frac{s_y}{s_x} \\;=\\; (-0.8485)\\frac{16.9}{26.7} \\approx -0.536. \\] Intercept: \\[ b_0 = \\bar y - b_1 \\bar x \\;=\\; 38.8 - (-0.536)(30.8) \\approx 55.3. \\] Thus the fitted line is \\[ \\hat y = 55.3 - 0.536\\,x. \\]\nFor a neighborhood with 0% reduced-fee lunches (\\(x=0\\)), the model predicts about 55.3% of bike riders wear helmets.\nFor each 1 percentage-point increase in the reduced-fee lunch rate, the predicted helmet-wearing rate decreases by about 0.536 percentage points.\nPredicted: \\[ \\hat y = 55.3 - 0.536(40) \\approx 33.9. \\] Residual: \\[ e = y - \\hat y = 40 - 33.9 \\approx 6.1. \\] Interpretation: This neighborhood’s helmet-wearing rate is about 6.1 percentage points higher than the model predicts given its reduced-fee lunch rate.\n\n\n\n2.7 Question 8.44\n\nBecause the point \\((\\bar x,\\bar y)\\) lies on the least-squares line, \\[\n\\bar y=\\hat\\beta_0+\\hat\\beta_1\\bar x\n\\;\\Rightarrow\\;\n\\hat\\beta_1=\\frac{\\bar y-\\hat\\beta_0}{\\bar x}\n        =\\frac{3.9983-4.010}{-0.0883}\n        \\approx 0.133.\n\\] So the fitted model is \\[\n\\widehat{\\text{eval}} = 4.010 + 0.133\\,(\\text{beauty}).\n\\]\nThe regression output reports \\(t=4.13\\) with \\(p&lt;0.0001\\) for the beauty coefficient. Since the \\(p\\)-value is far below 0.05, we have convincing evidence that the slope is positive: higher (standardized) beauty scores are associated with higher teaching evaluations.\n\n\n\nLinearity: The scatterplot of evaluation vs. beauty shows a roughly linear trend.\nNormal residuals: The residual histogram is approximately symmetric and centered at 0 with no outliers.\nConstant variance: The residuals vs. beauty plot shows a fairly constant spread across the range of \\(x\\).\nIndependence: The residuals vs. order plot shows no pattern.\n\nGiven these diagnostics, the simple linear regression assumptions are satisfied.",
    "crumbs": [
      "Homework Solutions",
      "Homework 6 Answers"
    ]
  },
  {
    "objectID": "homework/hw4_answer.html",
    "href": "homework/hw4_answer.html",
    "title": "Homework 4 Answers",
    "section": "",
    "text": "If you find any typos or errors, please feel free to contact me via email at r13323002@ntu.edu.tw. I would appreciate it and will correct the solution to prevent any misunderstandings.\nFor some R commands marked with ‘OPTIONAL,’ you don’t need to learn them. You will be completely fine on the computer quiz even if you choose to ignore them.\nIf you’re having trouble understanding the code, don’t hesitate to ask me for help. I’ll do my best to assist you during office hours or after the TA session.",
    "crumbs": [
      "Homework Solutions",
      "Homework 4 Answers"
    ]
  },
  {
    "objectID": "homework/hw4_answer.html#computer-exercises",
    "href": "homework/hw4_answer.html#computer-exercises",
    "title": "Homework 4 Answers",
    "section": "1 Computer Exercises",
    "text": "1 Computer Exercises\n\n1.1 Null and Alternative Hypothesis\n\\[\n\\begin{cases}\nH_0&: \\text{Answers are independent of party affiliation.}\\\\\nH_1&: \\text{Answers are NOT independent of party affiliation.}\n\\end{cases}\n\\]\n\n\n1.2 Contingency Table and Chi-square Test\n# create two-way table (column percentage)\ncount_table &lt;- table(body$answer, body$party_affiliation,\n                     dnn = c(\"Asnwer\", \"Party Affiliation\"))\npct_table &lt;- prop.table(count_table, margin = 2)\nprint(pct_table)\n\n# chi-square test\nchi_test &lt;- chisq.test(pct_table)\nprint(chi_test)\n\n\n                         Party Affiliation\nAsnwer                      Democrat Independent Republican\n  do not know / no answer 0.04065041  0.04888889 0.05031447\n  should                  0.81029810  0.78000000 0.83018868\n  should not              0.14905149  0.17111111 0.11949686\n\n\n\n    Pearson's Chi-squared test\n\ndata:  pct_table\nX-squared = 0.011904, df = 4, p-value = 1\n\n\n\n\n1.3 Conclusion\nSince the p-value is 0.3598, which is larger than 0.05 , we do not reject the null hypothesis. That is, we don’t have strong evidence that shows an association between answers and party affiliations.",
    "crumbs": [
      "Homework Solutions",
      "Homework 4 Answers"
    ]
  },
  {
    "objectID": "homework/hw4_answer.html#textbook-exercise",
    "href": "homework/hw4_answer.html#textbook-exercise",
    "title": "Homework 4 Answers",
    "section": "2 Textbook Exercise",
    "text": "2 Textbook Exercise\n\n2.1 Question 6.6\n\nWith a random sample from &lt; 10% of the population, independence is satisfied. The success–failure condition is also satisfied. Hence, the margin of error can be calculated as follows:\n\n\\[\nME \\;=\\; z^* \\sqrt{\\frac{p(1-p)}{n}}\n\\;=\\; 1.96 \\times \\sqrt{\\frac{0.66 \\times 0.34}{1018}}\n\\;=\\; 0.029 \\approx 3\\%.\n\\]\n\nA 95% confidence interval for the proportion of adults who think that licensed drivers should be required to re-take their road test once they reach 65 years of age is\n\n\\[\n0.66 \\pm 0.03 \\;=\\; (0.63,\\; 0.69).\n\\]\nSince 70% is not contained in the interval, we would reject a null hypothesis where (p=0.7). Therefore, the data do not provide evidence that more than 70% of the population think that drivers over the age of 65 should re-take their road test.\n\n\n2.2 Question 6.8\n\nThe population parameter of interest is the proportion of all Greeks who would rate their lives poorly enough to be considered “suffering”, (p). The point estimate for this parameter is the proportion of Greeks in this sample who would rate their lives as such, (p = 0.25).\nConditions:\n\n\nIndependence: The sample is random, and (1000 &lt; 10%) of all Greeks, therefore the life rating of one Greek in this sample is independent of another.\n\nSuccess–failure: (1000 = 250 &gt; 10) and (1000 = 750 &gt; 10).\nSince the observations are independent and the success–failure condition is met, (p) is expected to be approximately normal.\n\n\nA 95% confidence interval can be calculated as follows:\n\n\\[\n\\hat p \\pm z^* \\sqrt{\\frac{\\hat p(1-\\hat p)}{n}}\n= 0.25 \\pm 1.96 \\times \\sqrt{\\frac{0.25 \\times 0.75}{1000}}\n= 0.25 \\pm 0.0269\n= (0.2231,\\; 0.2769).\n\\]\nWe are 95% confident that approximately 22% to 28% of Greeks would rate their lives poorly enough to be considered “suffering”.\n\nIncreasing the confidence level would increase the margin of error, hence widen the interval.\nIncreasing the sample size would decrease the margin of error, hence make the interval narrower.\n\n\n\n2.3 Question 6.26\n\nThe hypotheses are\n\n\\[\n\\left\\{\n\\begin{aligned}\nH_0 &: \\; p_R = p_D \\; (\\text{Proportions of Republicans and Democrats who support the use of full-body scans are equal.}) \\\\\nH_A &: \\; p_R \\ne p_D \\; (\\text{Proportions of Republicans and Democrats who support the use of full-body scans are different.})\n\\end{aligned}\n\\right.\n\\]\nThe pooled proportion can be calculated as follows:\n\\[\n\\hat{p}_{\\text{pool}}\n= \\frac{\\text{success}_R + \\text{success}_D}{n_R + n_D}\n= \\frac{264 + 299}{318 + 369}\n= \\frac{563}{687}\n\\approx 0.82\n\\]\nNext we calculate the test statistic,\n\\[\n\\hat{p}_R=\\frac{264}{318}=0.83,\\qquad\n\\hat{p}_D=\\frac{299}{369}=0.81\n\\]\n\\[\nZ\n= \\frac{\\hat{p}_R-\\hat{p}_D}\n{\\sqrt{\\hat{p}_{\\text{pool}}\\,(1-\\hat{p}_{\\text{pool}})\\left(\\frac{1}{n_R}+\\frac{1}{n_D}\\right)}}\n= \\frac{0.83-0.81}{\\sqrt{0.82\\times 0.18\\left(\\frac{1}{318}+\\frac{1}{369}\\right)}}\n= \\frac{0.02}{0.0294}\n= 0.68\n\\]\nand the p-value:\n\\[\np-\\text{value}\n= P\\big(|\\hat{p}_R-\\hat{p}_D|&gt;0.02 \\mid H_0\\big)\n= P(|Z|&gt;0.68)\n= 2 \\times 0.2483\n= 0.4966\n\\]\nSince the p-value is high, we fail to reject \\(H_0\\). The data do not provide strong evidence that the proportions of Republicans and Democrats who support the use of full-body scans are different.\n\nWe may have made a Type II error, since we may have incorrectly failed to reject \\(H_0\\).\n\n\n\n2.4 Question 6.40\n\nMultiply each percent by 701:\n\n\n\n\n\nDownload\nNo Download\n\n\n\n\nPositions 1\n97\n128\n\n\nPositions 2\n102\n130\n\n\nPositions 3\n85\n159\n\n\n\n\nPrepare. It is convenient to construct the actual table we care about, which will represent the totals in the three experiment groups:\n\n\n\n\nGroup\nTotal\n\n\n\n\nPositions 1\n225\n\n\nPositions 2\n232\n\n\nPositions 3\n244\n\n\n\nThis now looks like a goodness of fit chi-square problem. As part of our Prepare step, we should also construct the hypotheses.\n\\[\n\\left\\{\n\\begin{aligned}\nH_0 &: \\text{ The chance a user is in any experiment group is equal among the three groups.}\\\\\nH_A &: \\text{ The chance of being in one group or another varies by the group.}\n\\end{aligned}\n\\right.\n\\]\nCheck. If \\(H_0\\) were true, then we’d expect \\(1/3\\) of the 701 visitors to be in each group, i.e. \\(233.67\\) in each group. The \\(233.67\\) is greater than 5 for all three groups, satisfying one of the required conditions. The independence condition is also satisfied since each visitor was randomly assigned to a group and only counted once in the table. With the conditions satisfied, we can move forward with conducting a goodness-of-fit chi-square test.\nCalculate. We can compute the test statistic and degrees of freedom:\n\\[\n\\chi^2\n= \\frac{(255-233.67)^2}{233.67}\n+ \\frac{(232-233.67)^2}{233.67}\n+ \\frac{(244-233.67)^2}{233.67}\n= 0.79\n\\]\n\\[\ndf = 3-1 = 2\n\\]\nUsing software, we can identify the tail area as \\(0.67\\).\nConclude. Because the p-value is larger than \\(0.05\\), we do not reject \\(H_0\\). That is, we do not see any evidence that visitor randomization to the groups is imbalanced / malfunctioning.\n\n\nPrepare.\n\n\\[\n\\left\\{\n\\begin{aligned}\nH_0 &: \\text{ No difference in download rate across the experiment groups.}\\\\\nH_A &: \\text{ There is some difference in download rate across the groups.}\n\\end{aligned}\n\\right.\n\\]\nCheck. Each visitor was randomly assigned to a group and only counted once in the table, so the observations are independent. The expected counts can also be computed by constructing row and column totals, then multiplying these (and dividing by the table total) to get the expected counts under \\(H_0\\). Those expected counts are (reading down the first column then down the second): 91.2, 94.0, 98.9, 133.8, 138.0, 145.2. All of these expected counts are at least 5. Therefore, we can use the chi-square test.\nCalculate. We can calculate the test statistic as\n\\[\n\\chi^2\n= \\frac{(97-91.2)^2}{91.2}\n+ \\cdots\n+ \\frac{(159-145.2)^2}{145.2}\n= 5.04\n\\]\nwith \\(df=(3-1)\\times(2-1)=2\\). This results in a p-value of \\(0.08\\), which we can find using software.\nConclude. Because the p-value is less than \\(0.05\\), we do not reject \\(H_0\\). That is, we have not found evidence that there is any difference in the download rate depending on the download link position.\n\n\n2.5 Question 6.42\n\nThe hypotheses are as follows:\n\n\\[\n\\left\\{\n\\begin{aligned}\nH_0 &: p = 0.5 \\ \\ (50\\% \\text{ of Americans think the Civil War is still relevant})\\\\\nH_A &: p \\ne 0.5 \\ \\ (\\text{A majority of Americans hold an opinion (for or against) that the Civil War is still relevant.})\n\\end{aligned}\n\\right.\n\\]\nBefore calculating the test statistic we should check that the conditions are satisfied:\n\nIndependence: The sample is random, and 1,507 \\(&lt;10\\%\\) of all Americans, therefore whether or not one American in the sample thinks the Civil War is still relevant is independent of another.\n\nSuccess-failure: \\(1,507 \\times 0.50 = 753.5 &gt; 10\\) and \\(1,507 \\times 0.50 = 753.5 &gt; 10\\). Since the observations are independent and the success-failure condition is met, \\(\\hat{p}\\) is expected to be approximately normal.\n\nThe test statistic and the p-value can be calculated as follows:\n\\[\nZ = \\frac{\\hat{p}-p_0}{\\sqrt{\\dfrac{p_0(1-p_0)}{n}}}\n= \\frac{0.56-0.5}{\\sqrt{\\dfrac{0.5\\times 0.5}{1{,}507}}}\n= \\frac{0.06}{0.0129}\n= 4.65\n\\]\n\\[\np\\text{–value} = P(\\hat{p} &gt; 0.56 \\mid p=0.5) = P(|Z|&gt;4.65) \\approx 0\n\\]\nSince the p-value is very small, we reject \\(H_0\\). Since the data show \\(\\hat{p} &gt; 0.5\\) and we’ve rejected \\(H_0\\), the data provide strong evidence that the majority of the Americans think the Civil War is still relevant.\n\nIf in fact only \\(50\\%\\) of Americans thought the Civil War is still relevant, the probability of obtaining a random sample of \\(1,507\\) Americans where \\(56\\%\\) or more think it is still relevant would be approximately \\(0\\).\nFirst we need to recheck the success-failure condition using the sample proportion:\n\\(1,507 \\times 0.56 = 843.92 &gt; 10\\) and \\(1,507 \\times 0.44 = 663.08 &gt; 10\\). A \\(90\\%\\) confidence interval can be calculated as follows:\n\n\\[\n\\hat{p} \\pm z^\\star \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\n= 0.56 \\pm 1.65 \\sqrt{\\frac{0.56\\times 0.44}{1{,}507}}\n\\]\n\\[\n= 0.56 \\pm 1.65 \\times 0.0128\n= 0.56 \\pm 0.02\n= (0.54,\\; 0.58)\n\\]\nWe are \\(90\\%\\) confident that \\(54\\%\\) to \\(58\\%\\) of all Americans think that the Civil War is still relevant. This agrees with the conclusion of the earlier hypothesis test since the interval lies above \\(50\\%\\).\n\n\n2.6 Question 6.50\n\nChi-squared test of independence.\nThe hypotheses are:\n\n\\[\n\\left\\{\n\\begin{aligned}\nH_0 &: \\text{Caffeinated coffee consumption and depression in women are independent.}\\\\\nH_A &: \\text{Caffeinated coffee consumption and depression in women are dependent/associated.}\n\\end{aligned}\n\\right.\n\\]\n\nDepression: \\(\\dfrac{2607}{50739}=0.0514\\)\n\nNo depression: \\(1-0.0514=0.9486\\)\n\nWe have:\n\n\\[\nE=\\frac{2607 \\times 6617}{50739}=339.9854 \\approx 340\n\\]\n\\[\n\\frac{(O-E)^2}{E}=\\frac{(373-340)^2}{340}=3.20\n\\]\n\n\\(\\text{df}=(R-1)\\times(C-1)=1\\times 4=4\\), and \\(p\\)-value \\(&lt;0.001\\).\nThe \\(p\\)-value is small and we reject \\(H_0\\). The data provide convincing evidence to suggest that caffeinated coffee consumption and depression in women are associated.\nYes, this is an observational study. Based on this study we can’t deduce that drinking more coffee leads to less depression. There may be other factors, lurking variables, that cause decreased depression in women who drink more coffee.",
    "crumbs": [
      "Homework Solutions",
      "Homework 4 Answers"
    ]
  },
  {
    "objectID": "homework/hw2_answer.html",
    "href": "homework/hw2_answer.html",
    "title": "Homework 2 Answers",
    "section": "",
    "text": "If you find any typos or errors, please feel free to contact me via email at r13323002@ntu.edu.tw. I would appreciate it and will correct the solution to prevent any misunderstandings.\nFor some R commands marked with ‘OPTIONAL,’ you don’t need to learn them. You will be completely fine on the computer quiz even if you choose to ignore them.\nIf you’re having trouble understanding the code, don’t hesitate to ask me for help. I’ll do my best to assist you during office hours or after the TA session.",
    "crumbs": [
      "Homework Solutions",
      "Homework 2 Answers"
    ]
  },
  {
    "objectID": "homework/hw2_answer.html#computer-exercises",
    "href": "homework/hw2_answer.html#computer-exercises",
    "title": "Homework 2 Answers",
    "section": "1 Computer Exercises",
    "text": "1 Computer Exercises\n\n1.1 Bernoulli Simulation\n# simulate 1,000 coin flips by denoting head if value above 0.5, tail otherwise\ncoin_flips &lt;- runif(1000) &gt; 0.5\n\n# calculate cumulative number and fraction of heads for coin flips of 1, 2, 3, ..., 1000\ncum_heads &lt;- cumsum(coin_flips)\nfrac_heads &lt;- cum_heads / 1:1000\n\n# record the result of each flip in dataframe\ndf &lt;- data.frame(\n  flips = 1:1000,\n  coin_outcome = coin_flips,\n  cumulative_heads = cum_heads,\n  fraction_heads = frac_heads\n)\n\n# take a look at the fitst five records\nhead(df)\n\n\n  flips coin_outcome cumulative_heads fraction_heads\n1     1         TRUE                1      1.0000000\n2     2        FALSE                1      0.5000000\n3     3         TRUE                2      0.6666667\n4     4        FALSE                2      0.5000000\n5     5         TRUE                3      0.6000000\n6     6         TRUE                4      0.6666667\n\n\n# draw the fraction of head over each flip\nggplot(df, aes(x = flips, y = fraction_heads)) +\n  \n  ## draw the fraction of head\n  geom_line(color = \"steelblue\") +\n  \n  ## (OPTIONAL) baseline fraction is 0.5\n  geom_hline(aes(yintercept = 0.5), color = \"black\") +\n  \n  ## add label to make the graph more readable\n  labs(\n    title = \"Fraction of Heads in 1,000 Coin Flips\",\n    x = \"Number of Coin Flips\",\n    y = \"Fraction of Heads\"\n  ) +\n  \n  ## center the graph title\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\n\n\n1.2 Normal Simulation\n# define distribution parameters\nmu &lt;- 2\nsigma &lt;- 2.5\n\n# draw the random normal samples according to different sample size\ndraw_size20   &lt;- rnorm(20, mean = mu, sd = sigma)\ndraw_size100  &lt;- rnorm(100, mean = mu, sd = sigma)\ndraw_size500  &lt;- rnorm(500, mean = mu, sd = sigma)\ndraw_size1000 &lt;- rnorm(1000, mean = mu, sd = sigma)\n\n# compute the simulated mean and standard deviation according to different draw sizes\nsim_result &lt;- data.frame(\n  sample_size = c(20, 100, 500, 1000),\n  mean = c(mean(draw_size20), mean(draw_size100), mean(draw_size500), mean(draw_size1000)),\n  sd = c(sd(draw_size20), sd(draw_size100), sd(draw_size500), sd(draw_size1000))\n)\nprint(sim_result)\n\n\n  sample_size     mean       sd\n1          20 1.785653 2.632694\n2         100 2.363479 2.829786\n3         500 1.918210 2.483657\n4        1000 1.941324 2.556143\n\n\n# the histogram when draw size = 20\ndf_size20 &lt;- data.frame(\n  values = draw_size20\n)\nggplot(df_size20, aes(x = values)) +\n  geom_histogram()\n\n\n\n\n\n\n\n\n\n# the histogram when draw size = 100\ndf_size100 &lt;- data.frame(\n  values = draw_size100\n)\nggplot(df_size100, aes(x = values)) +\n  geom_histogram()\n\n\n\n\n\n\n\n\n\n# the histogram when draw size = 500\ndf_size500 &lt;- data.frame(\n  values = draw_size500\n)\nggplot(df_size500, aes(x = values)) +\n  geom_histogram()\n\n\n\n\n\n\n\n\n\n\n\n1.3 \n# the histogram when draw size = 1000\ndf_size1000 &lt;- data.frame(\n  values = draw_size1000\n)\nggplot(df_size1000, aes(x = values)) +\n  geom_histogram()\n\n\n\n\n\n\n\n\n\n\n\n1.4 Binomial Simulation\n# define distribution parameter and trial size\np &lt;- 0.1\nsample_num &lt;- 200\n\n# draw the random binomial samples according to different sample size\ndraw_size10   &lt;- rbinom(sample_num, size = 10,  prob = p)\ndraw_size50  &lt;- rbinom(sample_num, size = 50,  prob = p)\ndraw_size100  &lt;- rbinom(sample_num, size = 100, prob = p)\ndraw_size500 &lt;- rbinom(sample_num, size = 500, prob = p)\n\n# compute the simulated mean and standard deviation according to different draw sizes\nsim_result &lt;- data.frame(\n  sample_size = c(10, 50, 100, 500),\n  mean = c(mean(draw_size10), mean(draw_size50), mean(draw_size100), mean(draw_size500)),\n  sd = c(sd(draw_size10), sd(draw_size50), sd(draw_size100), sd(draw_size500))\n)\nprint(sim_result)\n\n\n  sample_size   mean        sd\n1          10  0.995 0.9999874\n2          50  4.900 2.0836767\n3         100 10.090 2.6603170\n4         500 50.025 6.5696405\n\n\n# the histogram when draw size = 10\ndf_size10 &lt;- data.frame(\n  values = draw_size10\n)\nggplot(df_size10, aes(x = values)) +\n  geom_histogram()\n\n\n\n\n\n\n\n\n\n# the histogram when draw size = 50\ndf_size50 &lt;- data.frame(\n  values = draw_size50\n)\nggplot(df_size50, aes(x = values)) +\n  geom_histogram()\n\n\n\n\n\n\n\n\n\n# the histogram when draw size = 100\ndf_size100 &lt;- data.frame(\n  values = draw_size100\n)\nggplot(df_size100, aes(x = values)) +\n  geom_histogram()\n\n\n\n\n\n\n\n\n\n# the histogram when draw size = 500\ndf_size500 &lt;- data.frame(\n  values = draw_size500\n)\nggplot(df_size500, aes(x = values)) +\n  geom_histogram()",
    "crumbs": [
      "Homework Solutions",
      "Homework 2 Answers"
    ]
  },
  {
    "objectID": "homework/hw2_answer.html#textbook-exercise",
    "href": "homework/hw2_answer.html#textbook-exercise",
    "title": "Homework 2 Answers",
    "section": "2 Textbook Exercise",
    "text": "2 Textbook Exercise\n\n2.1 Question 3.8\nWe denote Poverty Line as PL, and Foreign Language as FL.\n\nNo, there are people who are both living below the poverty line and speak a language other than English at home.\nThe Venn diagram is shown below.\n\n\n\n\n\n\n\nEach person living below the poverty line either speaks only English at home or doesn’t.\nSince 14.6% of Americans live below the poverty line and 4.2% speak a language other than English at home, the other 10.4% only speak English at home.\nUsing the General Addition Rule:\n\n\\[\n\\begin{aligned}\nP(\\text{below PL or speak FL})\n&= P(\\text{below PL}) + P(\\text{FL}) - P(\\text{both}) \\\\\n&= 0.146 + 0.207 - 0.042 \\\\\n&= 0.311.\n\\end{aligned}\n\\]\n\nProbability of neither below PL nor speak FL:\n\n\\[\nP(\\text{neither below PL nor speak FL})\n= 1 - P(\\text{below PL or speak FL})\n= 1 - 0.311\n= 0.689.\n\\]\n\nTwo approaches to assess independence:\n\n\n\nMultiplication rule (if independent)\n\n\\[\nP(\\text{below PL}) \\times P(\\text{FL})\n= 0.146 \\times 0.207\n= 0.030.\n\\]\nThis does not equal ( P() = 0.042 ), therefore the events are dependent.\n\nBayes’ theorem\n\nIf the two events were independent, then ( P() = P() ).\nUsing Bayes’ theorem:\n\\[\nP(\\text{below PL} \\mid \\text{FL})\n= \\frac{P(\\text{below PL and FL})}{P(\\text{FL})}\n= \\frac{0.042}{0.207}\n\\approx 0.203.\n\\]\nSince this probability (()) is different from ( P() = 0.146 ), we determine that the two events are dependent.\n\n\n2.2 Question 3.16\n\nNo, there are individuals who are both in excellent health and have health coverage.\nOverall probability: \\[ P(\\text{excellent health}) = 0.2329 \\]\nConditional on having health coverage: \\[\nP(\\text{excellent health}\\mid \\text{coverage}) =\n\\frac{0.2099}{0.8738} \\approx 0.24 \\]\nConditional on not having health coverage: \\[\nP(\\text{excellent health}\\mid \\text{no coverage}) =\n\\frac{0.0230}{0.1262} \\approx 0.18 \\]\nConclusion: Since the probability of excellent health differs between coverage groups (24% vs 18%), the variables are not independent.\n\n\n\n2.3 Question 3.34\n\nThe probability model and the calculation of average revenue per passenger (expected value)\n\n\n\n\nTable 1: Probability model for baggage fee revenue per passenger\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvent\n\\(X\\)\n(P(X))\n(XP(X))\n((X - E\\[X\\])^2)\n((X - E\\[X\\])^2P(X))\n\n\n\n\nNo baggage\n0\n0.54\n0.0\n246.49\n133.10\n\n\n1 checked bag\n25\n0.34\n8.5\n86.49\n29.41\n\n\n2 checked bags\n60\n0.12\n7.2\n1962.49\n235.50\n\n\n\n\n\n\n\nExpected value: \\[(E(X) = 15.70)\\]\nVariance: \\[(V(X) = 398.01)\\]\nStandard deviation: \\[(SD(X) = 19.95)\\]\n\n\nAssume independence between individual fliers (a rough but helpful approximation).\n\n\\[\\begin{aligned}\nE\\!\\left[\\textstyle\\sum_{i=1}^{120} X_i\\right]\n  &= \\sum_{i=1}^{120} E[X_i]\n  = 120 \\times 15.70\n  = \\$1{,}884 \\\\\nV\\!\\left[\\textstyle\\sum_{i=1}^{120} X_i\\right]\n  &= \\sum_{i=1}^{120} V[X_i]\n  = 120 \\times 398.01\n  = 47{,}761.20 \\\\\nSD\\!\\left[\\textstyle\\sum_{i=1}^{120} X_i\\right]\n  &= \\sqrt{47{,}761.20}\n  = 218.54\n\\end{aligned}\\]\n\n\n2.4 Question 3.44\n\n\n\n\n\\(E(X + Y_1 + Y_2 + Y_3) = E(X) + 3 \\times E(Y) = 48 + 3 \\times 2 = 54\\)\n\n\\(V(X + Y_1 + Y_2 + Y_3) = V(X) + 3 \\times V(Y) = 1 + 3 \\times 0.0625 = 1.1875\\)\n\n\\(SD(X + Y_1 + Y_2 + Y_3) = \\sqrt{1.1875} = 1.09\\)\n\n\n\n\n\n\\(E(X - Y) = E(X) - E(Y) = 48 - 2 = 46\\)\n\n\\(V(X - Y) = V(X) + V(Y) = 1 + 0.0625 = 1.0625\\)\n\n\\(SD(X - Y) = \\sqrt{1.0625} = 1.03\\)\n\n\nInitially we do not know exactly how much ice cream is in the box. Then we scoop out an unknown amount. We should now be even more unsure about the amount of ice cream that is left in the box.\n\n\n\n2.5 Question 4.4\n\nProblem setup\n\nLet \\(X\\) denote the finishing times of Men (ages 30–34) and \\(Y\\) denote the finishing times of Women (ages 25–29):\n\\[\nX \\sim N(\\mu = 4313, \\sigma = 583)\n\\] \\[\nY \\sim N(\\mu = 5261, \\sigma = 807)\n\\]\n\nZ-scores\n\nThe Z-scores can be calculated as follows:\n\\[\nZ_{Leo} = \\frac{4948 - 4313}{583} = 1.09\n\\] \\[\nZ_{Mary} = \\frac{5513 - 5261}{807} = 0.31\n\\]\n\nLeo finished 1.09 standard deviations above the mean of his group.\n\nMary finished 0.31 standard deviations above the mean of hers.\n\n\nComparison\n\nMary ranked better since her Z-score indicates a relatively shorter finishing time compared to her group.\n\nProbability for Leo\n\n\\[\nP(Z &gt; 1.09) = 1 - P(Z &lt; 1.09) = 1 - 0.8621 = 0.1379\n\\]\nSo, 13.79% of men in Leo’s age group performed worse.\n\nProbability for Mary\n\n\\[\nP(Z &gt; 0.31) = 1 - P(Z &lt; 0.31) = 1 - 0.6217 = 0.3783\n\\]\nSo, 37.83% of women in Mary’s age group performed worse.\n\nNormal model consideration\n\n\nThe answer to part (b) would not change since Z-scores can be calculated for non-normal distributions.\n\nHowever, parts (c) through (e) rely on the normal model and cannot be answered without it.\n\n\n\n2.6 Question 4.6\n\nFastest 5%\n\nThe fastest 5% are in the 5th percentile of the distribution.\nThe Z-score corresponding to the 5th percentile of a normal distribution is approximately \\(-1.65\\):\n\\[\nZ = -1.65 = \\frac{x - 4313}{583}\n\\]\n\\[\nx = -1.65 \\times 583 + 4313 = 3351 \\text{ seconds}\n\\]\nThe fastest 5% of males in this age group finished in less than 56 minutes.\n\nSlowest 10%\n\nThe slowest 10% are in the 90th percentile of the distribution.\nThe Z-score corresponding to the 90th percentile is approximately \\(1.28\\):\n\\[\nZ = 1.28 = \\frac{y - 5261}{807}\n\\]\n\\[\ny = 1.28 \\times 807 + 5261 = 6294 \\text{ seconds}\n\\]\nThe slowest 10% of females in this age group took 1 hour, 45 minutes, or longer to finish.\n\n\n2.7 Question 4.24\nLet \\(X \\sim \\text{Binomial}(n=3, p=0.25)\\) and for part (d) let \\(X \\sim \\text{Geometric}(p=0.25)\\) (counting the trial of the first success).\n\n\\(P(X=2)\\) with Binomial\n\n\\[\nP(X=2) = \\binom{3}{2}(0.25)^2(0.75)^1 = 0.1406\n\\]\n\n\\(P(X=0)\\) with Binomial\n\n\\[\nP(X=0) = \\binom{3}{0}(0.25)^0(0.75)^3 = 0.4219\n\\]\n\n\\(P(X \\ge 1)\\) with Binomial\n\n\\[\nP(X \\ge 1) = 1 - P(X=0) = 1 - 0.4219 = 0.5781\n\\]\n\nFirst success on trial 3 (Geometric)\n\n\\[\nP(X=3) = (1-p)^{3-1}p = (0.75)^2(0.25) = 0.1406\n\\]\n\n\n2.8 Question 4.28\n\nNegative Binomial Distribution\n\nUsing the negative binomial distribution with \\(n = 15\\) and \\(p = 0.65\\):\n\\[\nP(X = 10) = \\binom{14}{9}(0.65)^{10}(0.35)^{5} = 0.1416\n\\]\n\nBinomial Distribution\n\nUsing the binomial distribution:\n\\[\nP(X = 10) = \\binom{15}{10}(0.65)^{10}(0.35)^{5} = 0.2123\n\\]\n\nGeometric Distribution\n\nUsing the geometric distribution:\n\\[\nP(X = 3) = (0.35)^{2}(0.65) = 0.0796\n\\]",
    "crumbs": [
      "Homework Solutions",
      "Homework 2 Answers"
    ]
  },
  {
    "objectID": "example_code/Example_Code_wk14.html",
    "href": "example_code/Example_Code_wk14.html",
    "title": "Week 14 Example R Code (1202)",
    "section": "",
    "text": "Right click to download:\n\nwk14_example_code.R",
    "crumbs": [
      "Example R code",
      "Week 14 Example R Code (1202)"
    ]
  },
  {
    "objectID": "example_code/Example_Code_wk12.html",
    "href": "example_code/Example_Code_wk12.html",
    "title": "Week 12 Example R Code (1118)",
    "section": "",
    "text": "Right click to download:\n\nwk12_example_code.R",
    "crumbs": [
      "Example R code",
      "Week 12 Example R Code (1118)"
    ]
  },
  {
    "objectID": "example_code/Example_Code_wk10.html",
    "href": "example_code/Example_Code_wk10.html",
    "title": "Week 10 Example R Code (1104)",
    "section": "",
    "text": "Right click to download:\n\nwk10_example_code.R",
    "crumbs": [
      "Example R code",
      "Week 10 Example R Code (1104)"
    ]
  },
  {
    "objectID": "example_code/Example_Code_wk07.html",
    "href": "example_code/Example_Code_wk07.html",
    "title": "Week 7 Example R Code (1014)",
    "section": "",
    "text": "Right click to download:\n\nwk7_example_code.R",
    "crumbs": [
      "Example R code",
      "Week 7 Example R Code (1014)"
    ]
  },
  {
    "objectID": "example_code/Example_Code_wk05.html",
    "href": "example_code/Example_Code_wk05.html",
    "title": "Week 5 Example R Code (0930)",
    "section": "",
    "text": "Right click to download:\n\nwk5_example_code.R",
    "crumbs": [
      "Example R code",
      "Week 5 Example R Code (0930)"
    ]
  },
  {
    "objectID": "example_code/Example_Code_wk03.html",
    "href": "example_code/Example_Code_wk03.html",
    "title": "Week 3 Example R Code (0916)",
    "section": "",
    "text": "Right click to download:\n\nwk3_example_code.R",
    "crumbs": [
      "Example R code",
      "Week 3 Example R Code (0916)"
    ]
  },
  {
    "objectID": "example_code/Example_Code_wk01.html",
    "href": "example_code/Example_Code_wk01.html",
    "title": "Week 1 Example R Code (0902)",
    "section": "",
    "text": "Right click to download:\n\nwk1_example_code.R",
    "crumbs": [
      "Example R code",
      "Week 1 Example R Code (0902)"
    ]
  },
  {
    "objectID": "answers/wk12_answer.html",
    "href": "answers/wk12_answer.html",
    "title": "Week 12 Answers (1118)",
    "section": "",
    "text": "Remember to use the project and create a new script in your script folder!\nBetter to use only the functions taught in the course.",
    "crumbs": [
      "Practice Answers",
      "Week 12 Answers (1118)"
    ]
  },
  {
    "objectID": "answers/wk12_answer.html#reminders",
    "href": "answers/wk12_answer.html#reminders",
    "title": "Week 12 Answers (1118)",
    "section": "",
    "text": "Remember to use the project and create a new script in your script folder!\nBetter to use only the functions taught in the course.",
    "crumbs": [
      "Practice Answers",
      "Week 12 Answers (1118)"
    ]
  },
  {
    "objectID": "answers/wk12_answer.html#download-data",
    "href": "answers/wk12_answer.html#download-data",
    "title": "Week 12 Answers (1118)",
    "section": "2 Download Data",
    "text": "2 Download Data\nPlease download the datasets transactions.csv (right click here)",
    "crumbs": [
      "Practice Answers",
      "Week 12 Answers (1118)"
    ]
  },
  {
    "objectID": "answers/wk12_answer.html#silent-witch-chinmoku-no-majo-no-kakushigoto-silent-witch-沉默魔女的祕密",
    "href": "answers/wk12_answer.html#silent-witch-chinmoku-no-majo-no-kakushigoto-silent-witch-沉默魔女的祕密",
    "title": "Week 12 Answers (1118)",
    "section": "3 Silent Witch: Chinmoku no Majo no Kakushigoto (Silent Witch 沉默魔女的祕密)",
    "text": "3 Silent Witch: Chinmoku no Majo no Kakushigoto (Silent Witch 沉默魔女的祕密)\nMonica is the new accountant for the Serendia Academy’s student association. She suspects that cash vs non-cash transactions in 2024 look quite different from previous years, and worries there might be some false accounting going on.\nMonica sees a dataset transactions.csv with the following columns:\n\nyear: the year of the transaction (2015–2024)\n\npayment_type: \"cash\", \"bank_transfer\", or \"online\"\n\namount: transaction amount in dollars\n\nShe wants to use a chi-squared test to check if the distribution of payment types in 2024’s accounting is significantly different from the other years.\n\nUse the pipe %&gt;% in the steps below.\nCreate a new column period with two categories: pre_2024 for years 2015–2023, year_2024 for year 2024 only. Save the result as transactions_by2024.\n\nlibrary(tidyverse)\n\ntransactions &lt;- read.csv(\"data/transactions.csv\")\n\ntransactions_by2024 &lt;- transactions %&gt;%\n  mutate(\n    period = if_else(year == 2024, \"year_2024\", \"pre_2024\")\n  )\n\nUsing group_by() and summarise(), compute a table of the number and mean of transactions for each combination of period and payment_type from transactions_by2024.\n\nsummary_counts &lt;- transactions_by2024 %&gt;%\n  group_by(period, payment_type) %&gt;%\n  summarize(n = n(), \n            mean = mean(amount)\n            ) %&gt;%\n  ungroup()\n\n\n# A tibble: 6 × 4\n  period    payment_type      n  mean\n  &lt;chr&gt;     &lt;chr&gt;         &lt;int&gt; &lt;dbl&gt;\n1 pre_2024  bank_transfer   828  271.\n2 pre_2024  cash           1259  271.\n3 pre_2024  online          613  277.\n4 year_2024 bank_transfer    53  267.\n5 year_2024 cash            213  277.\n6 year_2024 online           34  244.\n\n\n\nFrom transactions_by2024, create a 2 × 3 contingency table tab (period × payment_type) using table().\n\ntab &lt;- table(transactions_by2024$period, \n             transactions_by2024$payment_type\n             )\n\n\n           \n            bank_transfer cash online\n  pre_2024            828 1259    613\n  year_2024            53  213     34\n\n\n\nUse chisq.test() on tab to test:\n\n\\(H_0\\): The distribution of payment_type is the same in pre_2024 and year_2024.\n\\(H_1\\): The distribution of payment_type is different in year_2024.\n\n\nchisq_result &lt;- chisq.test(tab)\n\n\n\n    Pearson's Chi-squared test\n\ndata:  tab\nX-squared = 64.405, df = 2, p-value = 1.034e-14\n\n\n\nReport the p-value from the chi-squared test. Is there false accounting in 2024?\n\nprint(chisq_result[[\"p.value\"]]) # reject the null hypothesis\n\n\n[1] 1.034198e-14",
    "crumbs": [
      "Practice Answers",
      "Week 12 Answers (1118)"
    ]
  },
  {
    "objectID": "answers/wk10_answer.html",
    "href": "answers/wk10_answer.html",
    "title": "Week 10 Answers (1104)",
    "section": "",
    "text": "Remember to use the project and create a new script in your script folder!\nBetter to use only the functions taught in the course.",
    "crumbs": [
      "Practice Answers",
      "Week 10 Answers (1104)"
    ]
  },
  {
    "objectID": "answers/wk10_answer.html#reminders",
    "href": "answers/wk10_answer.html#reminders",
    "title": "Week 10 Answers (1104)",
    "section": "",
    "text": "Remember to use the project and create a new script in your script folder!\nBetter to use only the functions taught in the course.",
    "crumbs": [
      "Practice Answers",
      "Week 10 Answers (1104)"
    ]
  },
  {
    "objectID": "answers/wk10_answer.html#clt-simulation",
    "href": "answers/wk10_answer.html#clt-simulation",
    "title": "Week 10 Answers (1104)",
    "section": "2 CLT Simulation",
    "text": "2 CLT Simulation\n\n2.1 Draw Poisson Sample\nWrite a function called sample_mean_pois(n) with the following specification:\n\nDraw \\(n\\) random samples from a Poisson distribution \\(\\lambda = 5\\).\nCompute the sample mean.\nReturn the sample mean.\n\nThis function allows you to draw \\(n\\) random samples from a Poisson distribution (\\(\\lambda=5\\)) and compute the sample mean.\nsample_mean_pois &lt;- function(n){\n  rdnum &lt;- rpois(n, lambda = 5)\n  return(mean(rdnum))\n}\n\n\n2.2 Build Sample Mean DataFrame\nNow, we’re going to utilize the function to help us compute the sample mean multiple times. Please follow the instructions step-by-step:\n\nSet the random seed to 2025.\nGiven \\(n=500\\), use the function replicate() to execute the function sample_mean_pois(n) we just defined for 1,000 times.\nAfter that, you should obtain 1,000 sample means. Assign the 1,000 sample means to a variable called rdmean and build a DataFrame from it.\n\nSo far, we have obtained \\(1,000\\) sample means, each calculated from \\(500\\) Poisson samples.\nset.seed(2025)\n\nrdmean &lt;- replicate(n = 1000, sample_mean_pois(500))\n\ndf &lt;- data.frame(\n  rdmean\n)\n\n\n2.3 Histogram\nUsing the DataFrame we just built, draw a histogram to examine the distribution of the sample means.\ndf %&gt;% ggplot(aes(x = rdmean)) +\n  geom_histogram()",
    "crumbs": [
      "Practice Answers",
      "Week 10 Answers (1104)"
    ]
  },
  {
    "objectID": "answers/wk07_answer.html",
    "href": "answers/wk07_answer.html",
    "title": "Week 7 Answers (1014)",
    "section": "",
    "text": "Remember to use the project and create a new script in your script folder!\nBetter to use only the functions taught in the course.",
    "crumbs": [
      "Practice Answers",
      "Week 7 Answers (1014)"
    ]
  },
  {
    "objectID": "answers/wk07_answer.html#reminders",
    "href": "answers/wk07_answer.html#reminders",
    "title": "Week 7 Answers (1014)",
    "section": "",
    "text": "Remember to use the project and create a new script in your script folder!\nBetter to use only the functions taught in the course.",
    "crumbs": [
      "Practice Answers",
      "Week 7 Answers (1014)"
    ]
  },
  {
    "objectID": "answers/wk07_answer.html#download-data",
    "href": "answers/wk07_answer.html#download-data",
    "title": "Week 7 Answers (1014)",
    "section": "2 Download Data",
    "text": "2 Download Data\nPlease download the datasets loan_full_schema.csv here.",
    "crumbs": [
      "Practice Answers",
      "Week 7 Answers (1014)"
    ]
  },
  {
    "objectID": "answers/wk07_answer.html#wrap-the-graph",
    "href": "answers/wk07_answer.html#wrap-the-graph",
    "title": "Week 7 Answers (1014)",
    "section": "3 Wrap the graph",
    "text": "3 Wrap the graph\nUse the dataset loans_full_schema.csv to create a histogram of the variable interest_rate. Set the bin width to 2.5, and facet the graph by the variable loan_purpose, and allow each sub-graph to have a different y-axis scale.\nlibrary(tidyverse)\n\nloan &lt;- read.csv(\"data/loans_full_schema.csv\")\ninterest_purpose_plot &lt;- ggplot(loan, aes(x = interest_rate)) +\n  geom_histogram(binwidth = 2.5) +\n  facet_wrap(~loan_purpose,\n             scales = \"free_y\"\n             )\n\nprint(interest_purpose_plot)",
    "crumbs": [
      "Practice Answers",
      "Week 7 Answers (1014)"
    ]
  },
  {
    "objectID": "answers/wk07_answer.html#save-the-graph",
    "href": "answers/wk07_answer.html#save-the-graph",
    "title": "Week 7 Answers (1014)",
    "section": "4 Save the graph",
    "text": "4 Save the graph\n\nCreate a folder figures in your project folder.\nSave the graph in the last question to the figures folder with name wk7_default_plot without any customized setting.\nSave another graph with name wk7_sized_plot using height = 6, width = 4.\nAdd assignment dpi = 150 to the last graph, and named the new graph as wk7_sized_plot_150dpi.\nCompare the differences between wk7_default_plot, wk7_sized_plot and wk7_sized_plot_150dpi.\n\n\n# Without any customized setting\nggsave(filename = \"wk7_default_plot.png\",\n       path = \"figures\",\n       plot = interest_purpose_plot.\n       )\n\n# Set height = 6, width = 4\nggsave(filename = \"wk7_sized_plot.png\",\n       path = \"figures\",\n       plot = interest_purpose_plot,\n       width = 6,\n       height = 4\n       )\n\n# Set dpi = 150\nggsave(filename = \"wk7_sized_plot_150dpi.png\",\n       path = \"figures\",\n       plot = interest_purpose_plot,\n       width = 6,\n       height = 4,\n       dpi = 150\n       )",
    "crumbs": [
      "Practice Answers",
      "Week 7 Answers (1014)"
    ]
  },
  {
    "objectID": "answers/wk05_answer.html",
    "href": "answers/wk05_answer.html",
    "title": "Week 5 Answers (0930)",
    "section": "",
    "text": "Remember to use the project and create a new script in your script folder!\nSet the seed to be 2025.\nBetter to use only the functions taught in the course.",
    "crumbs": [
      "Practice Answers",
      "Week 5 Answers (0930)"
    ]
  },
  {
    "objectID": "answers/wk05_answer.html#reminders",
    "href": "answers/wk05_answer.html#reminders",
    "title": "Week 5 Answers (0930)",
    "section": "",
    "text": "Remember to use the project and create a new script in your script folder!\nSet the seed to be 2025.\nBetter to use only the functions taught in the course.",
    "crumbs": [
      "Practice Answers",
      "Week 5 Answers (0930)"
    ]
  },
  {
    "objectID": "answers/wk05_answer.html#control-flow",
    "href": "answers/wk05_answer.html#control-flow",
    "title": "Week 5 Answers (0930)",
    "section": "2 Control Flow",
    "text": "2 Control Flow\nPrint out the characters \"NTU\" for four times, and then print out the characters \"National Taiwan University\" for six times.\n(There are multiple ways to accomplish this, but I encourage you to use a single for-loop and an if-else statement to complete the task so you can get familiar with these syntax.)\nfor (i in 1:10){\n  if (i &lt;= 4){\n    print(\"NTU\")\n  }else{\n    print(\"National Taiwan University\")\n  }\n}\n## [1] \"NTU\"\n## [1] \"NTU\"\n## [1] \"NTU\"\n## [1] \"NTU\"\n## [1] \"National Taiwan University\"\n## [1] \"National Taiwan University\"\n## [1] \"National Taiwan University\"\n## [1] \"National Taiwan University\"\n## [1] \"National Taiwan University\"\n## [1] \"National Taiwan University\"",
    "crumbs": [
      "Practice Answers",
      "Week 5 Answers (0930)"
    ]
  },
  {
    "objectID": "answers/wk05_answer.html#binomial-random-sample",
    "href": "answers/wk05_answer.html#binomial-random-sample",
    "title": "Week 5 Answers (0930)",
    "section": "3 Binomial Random Sample",
    "text": "3 Binomial Random Sample\n\nDraw 400 observations from binomial distribution [size = 1000, prob = 0.5] and compute the mean of the observations.\n\nset.seed(2025)\nsample_size &lt;- 400\nrdn &lt;- rbinom(n = sample_size, size = 1000, prob = 0.5)\nmean &lt;- mean(rdn)\nprint(mean)\n## [1] 499.2225\n\nUsing the random sample you just generated, create a DataFrame to store the drawn values by using data.frame() function, and draw the histogram graph to see the distribution.\n\nlibrary(ggplot2)\n\ndf &lt;- data.frame(\n  values = rdn\n)\nggplot(df, aes(x = values)) +\n  geom_histogram()",
    "crumbs": [
      "Practice Answers",
      "Week 5 Answers (0930)"
    ]
  },
  {
    "objectID": "answers/wk05_answer.html#certification-exam",
    "href": "answers/wk05_answer.html#certification-exam",
    "title": "Week 5 Answers (0930)",
    "section": "4 Certification Exam",
    "text": "4 Certification Exam\nA certification exam is organized for 10 students: Alice, Bob, Charlie, Diana, Ethan, Fiona, George, Hannah, Ivan, and Julia. Each student participates in 10 tests, named test_1, test_2, …, test_10. If the students pass certain amount of tests, they can claim the certificate.\n\nCreate a vector students that contains 10 students’ name.\nCreate a matrix scores that uses the rnorm() to generate students score in 10 tests (average score: 60, standard deviation: 15). Let the column name of the matrix be test_1, test_2, …, test_10.\n\n\n\n\n\n\n\nTipHint\n\n\n\nUse replicate() function to create the matrix first, create a character vector test_names for column names, then use colnames() to assign test_names as the column names of the matrix.\n\n\n\nCreate a dataframe stu_scores that combines students and scores.\n\n\n\n\n\n\n\nTipHint\n\n\n\ndata.frame(name = students, scores) is our new dataframe.\n\n\n\nCreate a function certificate_winner containing three parameters: data, passing_score, min_passed such that a student\n\npasses the test if the his/her score of that test is greater than or equal passing_score\nwins the certificate if the number of passing test is greater than or equal min_passed\n\nFinally, the function should return the students who wins the certificate.\n\n\n\n\n\n\n\nTipHint\n\n\n\nYou can use seq_along in the for-loop, such as for(i in seq_along(data[, 1])){}\n\n\n\n\n\n\n\n\nTipHint\n\n\n\nSet a counter that counts the number of tests the student passed in a for-loop. Remember to reset the counter to be 0 when the next loop begins.\n\n\n\n\n\n\n\n\nTipHint\n\n\n\nCreate a vector passed_students in the function that saves the student’s name if his/her meets the requirements.\n\n\n\nAnswer the following questions:\n\nWho are the certificate winner if passing_score is 60, and the passing_score is 5?\nWho are the certificate winner if passing_score is 65, and the passing_score is 6?\n\n\n# Part 1: Create student vector\nstudents &lt;- c(\"Alice\", \"Bob\", \"Charlie\", \"Diana\", \"Ethan\",\n              \"Fiona\", \"George\", \"Hannah\", \"Ivan\", \"Julia\")\n\n# Part 2: Create score matrix\ntest_names &lt;- c(\"test_1\", \"test_2\", \"test_3\", \"test_4\", \"test_5\",\n              \"test_6\", \"test_7\", \"test_8\", \"test_9\", \"test_10\")\n\n\nscores &lt;- replicate(10, rnorm(10, mean = 60, sd = 15))\n\ncolnames(scores) &lt;- test_names\n\n# Part 3: Create the dataframe that combines students and scores\nstu_scores &lt;- data.frame(name = students, scores)\n\n# Part 4: Create the certificate_winner function\ncertificate_winner &lt;- function(data, passing_score, min_passed){\n  \n  # Students names are in the first column\n  stu_vec &lt;- data[, 1]\n  \n  # Test names are in 2~11th columns\n  test_cols &lt;- colnames(data[, 2:11])\n  \n  # Counter for the number of exam passed\n  pass_count &lt;- 0\n  \n  # Students that wins the certificate\n  passed_students &lt;- c()\n  \n  # for i in 1:10\n  for(i in seq_along(stu_vec)){\n    \n    # Remember the counter should be reset for each student\n    pass_count &lt;- 0\n    \n    # for j in 1:10\n    for (j in seq_along(test_cols)){\n      \n      # Passed if score larger than passing_score\n      if(data[i, j+1] &gt;= passing_score){\n        \n        # Count how many tests student i passed\n        pass_count &lt;- pass_count + 1\n      }\n      \n    }\n      # Claims the certificate if number of exam passed &gt; minimum requirements\n      if(pass_count &gt;= min_passed){\n        \n        passed_students &lt;- c(passed_students, data[i, 1])\n        \n      }\n  }\n  \n  # Return the winners\n  return(passed_students)\n}\n\n# Question 1\nquestion_1_winners &lt;- certificate_winner(stu_scores, 60, 5)\nprint(question_1_winners)\n\n# Question 2\nquestion_2_winners &lt;- certificate_winner(stu_scores, 70, 6)\nprint(question_2_winners)\n#### Question 1 Answers\n## [1] \"Bob\"     \"Charlie\" \"Diana\"   \"Ethan\"   \"Fiona\"   \"Hannah\" \n#### Question 2 Answers\n## [1] \"Ethan\"",
    "crumbs": [
      "Practice Answers",
      "Week 5 Answers (0930)"
    ]
  },
  {
    "objectID": "answers/wk03_answer.html",
    "href": "answers/wk03_answer.html",
    "title": "Week 3 Answers (0916)",
    "section": "",
    "text": "Please download the datasets county.csv and loan_full_schema.csv here.",
    "crumbs": [
      "Practice Answers",
      "Week 3 Answers (0916)"
    ]
  },
  {
    "objectID": "answers/wk03_answer.html#download-data",
    "href": "answers/wk03_answer.html#download-data",
    "title": "Week 3 Answers (0916)",
    "section": "",
    "text": "Please download the datasets county.csv and loan_full_schema.csv here.",
    "crumbs": [
      "Practice Answers",
      "Week 3 Answers (0916)"
    ]
  },
  {
    "objectID": "answers/wk03_answer.html#coding-style",
    "href": "answers/wk03_answer.html#coding-style",
    "title": "Week 3 Answers (0916)",
    "section": "2 Coding Style",
    "text": "2 Coding Style\n\nCreate an RStudio project inside a folder with proper names (e.g. TA_Session).\nCreate folders for R scripts and data. (optional: put scripts for the first two weeks’ TA session in the script folder as well.)\nFor the following questions, your code should follow the coding styles in the slides.",
    "crumbs": [
      "Practice Answers",
      "Week 3 Answers (0916)"
    ]
  },
  {
    "objectID": "answers/wk03_answer.html#contingency-table",
    "href": "answers/wk03_answer.html#contingency-table",
    "title": "Week 3 Answers (0916)",
    "section": "3 Contingency Table",
    "text": "3 Contingency Table\nUsing the dataset loans_full_schema.csv, create a contingency table by loan_purpose (set as row) and application_type (set as column), and add the sum row and sum column.\nloan   &lt;- read.csv(\"data/loans_full_schema.csv\")\ntable &lt;- table(loan$loan_purpose, loan$application_type)\ntable_sum &lt;- addmargins(table)\nprint(table_sum)\n##                      individual joint   Sum\n##   car                       116    15   131\n##   credit_card              1971   278  2249\n##   debt_consolidation       4289   855  5144\n##   home_improvement          566   114   680\n##   house                     146     5   151\n##   major_purchase            273    30   303\n##   medical                   128    34   162\n##   moving                     59    10    69\n##   other                     793   121   914\n##   renewable_energy            9     1    10\n##   small_business            101    24   125\n##   vacation                   54     8    62\n##   Sum                      8505  1495 10000",
    "crumbs": [
      "Practice Answers",
      "Week 3 Answers (0916)"
    ]
  },
  {
    "objectID": "answers/wk03_answer.html#bar-graph",
    "href": "answers/wk03_answer.html#bar-graph",
    "title": "Week 3 Answers (0916)",
    "section": "4 Bar Graph",
    "text": "4 Bar Graph\nUsing the dataset loans_full_schema.csv, draw the bar graph to show the numbers of applicant according to each credit grade by following procedures:\n\nSpecify sub_grade as the x-axis, and fill the bar with grade.\nAdd graph title and axis labels\n\nTitle: Number of Applicant by Credit Grade\n\nx-axis: Credit Grade\n\ny-axis: Number of Applicant\n\nCenter the graph title.\n\n\n\n\n\n\n\nTipHint\n\n\n\nHint: Add theme(plot.title = element_text(hjust = 0.5)) to the graph.\n\n\nAfter that, you should have a beautiful graph and share it with me! :)\nggplot(loan, aes(x = sub_grade, fill = grade)) +\n  geom_bar() +\n  labs(\n    x = \"Credit Grade\",\n    y = \"Number of Applicant\",\n    title = \"Number of Applicant by Credit Grade\"\n  ) +\n  theme(plot.title = element_text(hjust = 0.5))",
    "crumbs": [
      "Practice Answers",
      "Week 3 Answers (0916)"
    ]
  },
  {
    "objectID": "answers/wk01_answer.html",
    "href": "answers/wk01_answer.html",
    "title": "Week 1 Answers (0902)",
    "section": "",
    "text": "Create two variables called x and y, and assign values 20250902 and 1031. Compute x / y.\nx &lt;- 20250902\ny &lt;- 1031\nprint(x / y)",
    "crumbs": [
      "Practice Answers",
      "Week 1 Answers (0902)"
    ]
  },
  {
    "objectID": "answers/wk01_answer.html#assign-values",
    "href": "answers/wk01_answer.html#assign-values",
    "title": "Week 1 Answers (0902)",
    "section": "",
    "text": "Create two variables called x and y, and assign values 20250902 and 1031. Compute x / y.\nx &lt;- 20250902\ny &lt;- 1031\nprint(x / y)",
    "crumbs": [
      "Practice Answers",
      "Week 1 Answers (0902)"
    ]
  },
  {
    "objectID": "answers/wk01_answer.html#help",
    "href": "answers/wk01_answer.html#help",
    "title": "Week 1 Answers (0902)",
    "section": "2 Help",
    "text": "2 Help\nUse the help() function to check docs, e.g. data.frame() or mean().\nhelp(data.frame)\nhelp(mean)",
    "crumbs": [
      "Practice Answers",
      "Week 1 Answers (0902)"
    ]
  },
  {
    "objectID": "answers/wk01_answer.html#matrix",
    "href": "answers/wk01_answer.html#matrix",
    "title": "Week 1 Answers (0902)",
    "section": "3 Matrix",
    "text": "3 Matrix\nCreate the following vectors:\nname_vec &lt;- c(\"James\", \"Noc\", \"Monica\")\n\nage_vec &lt;- c(25, 30, 28)\nand create a 3 × 2 matrix with these two vectors.\nDo you encounter errors? Can you print the matrix out? What’s the data type of the matrix?\nname_vec &lt;- c(\"James\", \"Noc\", \"Monica\")\nage_vec &lt;- c(25, 30, 28)\nmat &lt;- matrix(c(name_vec, age_vec), nrow = 3)\nprint(mat)\nclass(mat)\n\n# `mat[,2]` only select the second column\n# note that the `age_vec` become character type after merging into matrix\nprint(mat[,2])\nclass(mat[,2])",
    "crumbs": [
      "Practice Answers",
      "Week 1 Answers (0902)"
    ]
  },
  {
    "objectID": "practices/wk13.html",
    "href": "practices/wk13.html",
    "title": "Week 13 Practices (1125)",
    "section": "",
    "text": "Remember to use the project and create a new script in your script folder!\nBetter to use only the functions taught in the course.",
    "crumbs": [
      "Practices",
      "Week 13 Practices (1125)"
    ]
  },
  {
    "objectID": "practices/wk13.html#reminders",
    "href": "practices/wk13.html#reminders",
    "title": "Week 13 Practices (1125)",
    "section": "",
    "text": "Remember to use the project and create a new script in your script folder!\nBetter to use only the functions taught in the course.",
    "crumbs": [
      "Practices",
      "Week 13 Practices (1125)"
    ]
  },
  {
    "objectID": "practices/wk13.html#shangri-la-frontier-香格里拉開拓異境",
    "href": "practices/wk13.html#shangri-la-frontier-香格里拉開拓異境",
    "title": "Week 13 Practices (1125)",
    "section": "2 Shangri-La Frontier (香格里拉·開拓異境)",
    "text": "2 Shangri-La Frontier (香格里拉·開拓異境)\nShangri-La Frontier is a cutting-edge VRMMO game. After a major update, Sunraku is testing a new build and wants to know whether it actually increases his average damage per combo compared to his old build, which had a known average of 1200 damage per combo in similar areas.\nSunraku goes to a stable grinding spot and records the damage per combo for 15 battles using the new build:\n\\[\n1310, 1195, 1240, 1285, 1220,\n1350, 1290, 1210, 1265, 1305,\n1330, 1275, 1255, 1190, 1320\n\\]\n\nRun an appropriate one-sample t-test using t.test(), and report a 95% confidence interval for the mean damage with the form: 95 percent confidence interval: (a, b).\n\nPsyger-0 is another top-tier player in Shangri-La Frontier, known for her insane burst damage. She tests her own optimized build in the same area and logs her damage per combo in 12 battles:\n\\[\n1380, 1425, 1405, 1360, 1390,\n1435, 1410, 1375, 1440, 1400,\n1395, 1420\n\\]\n\nDoes Psyger-0’s build have a different mean damage than Sunraku’s new build? Report the p-value.",
    "crumbs": [
      "Practices",
      "Week 13 Practices (1125)"
    ]
  },
  {
    "objectID": "practices/wk11.html",
    "href": "practices/wk11.html",
    "title": "Week 11 Practices (1111)",
    "section": "",
    "text": "Remember to use the project and create a new script in your script folder!\nBetter to use only the functions taught in the course.",
    "crumbs": [
      "Practices",
      "Week 11 Practices (1111)"
    ]
  },
  {
    "objectID": "practices/wk11.html#reminders",
    "href": "practices/wk11.html#reminders",
    "title": "Week 11 Practices (1111)",
    "section": "",
    "text": "Remember to use the project and create a new script in your script folder!\nBetter to use only the functions taught in the course.",
    "crumbs": [
      "Practices",
      "Week 11 Practices (1111)"
    ]
  },
  {
    "objectID": "practices/wk11.html#download-data",
    "href": "practices/wk11.html#download-data",
    "title": "Week 11 Practices (1111)",
    "section": "2 Download Data",
    "text": "2 Download Data\nPlease download the datasets garden_shifts.csv (right click here)",
    "crumbs": [
      "Practices",
      "Week 11 Practices (1111)"
    ]
  },
  {
    "objectID": "practices/wk11.html#isekai-nonbiri-nouka-異世界悠閒農家",
    "href": "practices/wk11.html#isekai-nonbiri-nouka-異世界悠閒農家",
    "title": "Week 11 Practices (1111)",
    "section": "3 Isekai Nonbiri Nouka (異世界悠閒農家)",
    "text": "3 Isekai Nonbiri Nouka (異世界悠閒農家)\nHiraku is the village head of Taiju no mura (大樹村) and owns a big farmland. He keeps a log of when each villager — Hiraku, Rurushi, Tia, Ria, Daga, Fraurem, Senna — is responsible for a plot. However, because the log was kept by hand and then typed in, the dates are a bit messy and some entries are incomplete.\nHiraku sees a dataset garden_shifts.csv with the following columns:\n\nname: villager name\nstart_str: start date of the shift\n\nend_str: end date of the shift\nplot: which plant/plot they look after\n\nAll shifts are in September and October 2025, and no villager works on more than one plot on the same day.\nHiraku wants to know how many days each villager works in October.\n\nUse the pipe %&gt;% in the steps below.\nCreate a new data frame shifts_complete that adds two new columns, start_date and end_date, which convert start_str and end_date to Date types for the original data.\n\n\n\n\n\n\n\nTipHint\n\n\n\nRemember to keep NA as NA when using mutate().\n\n\n\n\n\n\n\n\nTipHint\n\n\n\nUse grepl(\"-\", start_str) ~ in case_when().\n\n\n\nDrops any rows containing NA (in any column) in shifts_complete .\nCreate a new data frame shifts_coverage that includes the full sequence of dates from start_date to end_date in shifts_coverage.\n\n\n\n\n\n\n\nTipHint\n\n\n\nFor example, if Hiraku is responsible for cabbage from 2025-09-10 to 2025-09-13, then there would be 4 rows that take value 2025-09-10, 2025-09-11, 2025-09-12 and 2025-09-13 in column date for shifts_complete.\n\n\n\n\n\n\n\n\nTipHint\n\n\n\nFor each row in shifts_complete, create a temperate data frame temp in the for-loop with columns name, plot, date, where date columns includes all the dates between start_date and end_date.\n\n\n\n\n\n\n\n\nTipHint\n\n\n\nUse rbind() to combine data frames in each loop.\n\n\n\nAdd a column month to shifts_coverage that contains only the YYYY-MM part of column date.\nCreate a new data frame shifts_coverage_oct for dates in October only.\nHow many days does each villager work in October?",
    "crumbs": [
      "Practices",
      "Week 11 Practices (1111)"
    ]
  },
  {
    "objectID": "practices/wk09.html",
    "href": "practices/wk09.html",
    "title": "Week 9 Practices (1028)",
    "section": "",
    "text": "Remember to use the project and create a new script in your script folder!\nBetter to use only the functions taught in the course.",
    "crumbs": [
      "Practices",
      "Week 9 Practices (1028)"
    ]
  },
  {
    "objectID": "practices/wk09.html#reminders",
    "href": "practices/wk09.html#reminders",
    "title": "Week 9 Practices (1028)",
    "section": "",
    "text": "Remember to use the project and create a new script in your script folder!\nBetter to use only the functions taught in the course.",
    "crumbs": [
      "Practices",
      "Week 9 Practices (1028)"
    ]
  },
  {
    "objectID": "practices/wk09.html#download-data",
    "href": "practices/wk09.html#download-data",
    "title": "Week 9 Practices (1028)",
    "section": "2 Download Data",
    "text": "2 Download Data\nPlease download the datasets restaurants.csv (right click here)",
    "crumbs": [
      "Practices",
      "Week 9 Practices (1028)"
    ]
  },
  {
    "objectID": "practices/wk09.html#nohara-hiroshi-hiru-meshi-no-ryuugi-野原廣志-午餐的流派",
    "href": "practices/wk09.html#nohara-hiroshi-hiru-meshi-no-ryuugi-野原廣志-午餐的流派",
    "title": "Week 9 Practices (1028)",
    "section": "3 Nohara Hiroshi: Hiru Meshi no Ryuugi (野原廣志 午餐的流派)",
    "text": "3 Nohara Hiroshi: Hiru Meshi no Ryuugi (野原廣志 午餐的流派)\n“My name is Hiroshi Nohara (野原廣志). I’m an office worker and often eat lunch out. Based on the state of my body and my wallet, I quickly decide what to eat each day. You could say that while I’m a business expert, I’m also a lunch expert.”\nHiroshi keeps a list of restaurants in restaurants.csv. The file has five columns:\n\nname: The restaurant’s name.\ntype: The type of cuisine.\nclosed: The restaurant’s closed day; some restaurants are permanently closed.\nlunch_set: Whether the restaurant offers lunch sets at noon.\nrating: Hiroshi’s personal rating for the restaurant.\n\nToday is Thursday. Hiroshi feels like seafood, but curry or noodles would also be fine. Since he had fast food yesterday, he’d rather avoid it today. It’s close to the end of the month, so it would be better if the restaurant offers lunch sets.\nFollow the instructions below to help Hiroshi choose the restaurants that best fit his needs:\n\n\n\n\n\n\nTipHint\n\n\n\nIn this practice, filter(), select(), mutate(), arrange() will all be used.\n\n\n\nUse the pipe %&gt;% in the steps below.\nFilter the restaurants that are open today.\nAdd a column lunch_set_score that is 1.5 if the restaurant offers lunch sets and 0 otherwise.\nAdd a column preference_score that takes value 1.5 for seafood, 1 for curry and noodle, -2 for fastfood, and 0 otherwise.\nAdd a column total_score that sums up the columns rating, lunch_set_score and preference_score.\nRemove the lunch_set_score and preference_score columns.\nArrange the rows in descending order of total_score.\nPrint the top 5 rows with the highest total_score.",
    "crumbs": [
      "Practices",
      "Week 9 Practices (1028)"
    ]
  },
  {
    "objectID": "practices/wk06.html",
    "href": "practices/wk06.html",
    "title": "Week 6 Practices (1007)",
    "section": "",
    "text": "Remember to use the project and create a new script in your script folder!\nSet the seed to be 2025.\nBetter to use only the functions taught in the course.",
    "crumbs": [
      "Practices",
      "Week 6 Practices (1007)"
    ]
  },
  {
    "objectID": "practices/wk06.html#reminders",
    "href": "practices/wk06.html#reminders",
    "title": "Week 6 Practices (1007)",
    "section": "",
    "text": "Remember to use the project and create a new script in your script folder!\nSet the seed to be 2025.\nBetter to use only the functions taught in the course.",
    "crumbs": [
      "Practices",
      "Week 6 Practices (1007)"
    ]
  },
  {
    "objectID": "practices/wk06.html#download-data",
    "href": "practices/wk06.html#download-data",
    "title": "Week 6 Practices (1007)",
    "section": "2 Download Data",
    "text": "2 Download Data\nPlease download the datasets ames.csv here.",
    "crumbs": [
      "Practices",
      "Week 6 Practices (1007)"
    ]
  },
  {
    "objectID": "practices/wk06.html#housing-price-in-2025",
    "href": "practices/wk06.html#housing-price-in-2025",
    "title": "Week 6 Practices (1007)",
    "section": "3 Housing Price in 2025",
    "text": "3 Housing Price in 2025\n\nUse paste() and for-loop to create a character vector date_2025 that contains 365 days in 2025, and each date repeat 3 times. i.e., c(\"2025-01-01\", \"2025-01-01\", \"2025-01-01\", ..., \"2025-12-31\")\n\n\n\n\n\n\n\nTipHint\n\n\n\nUse if (month %in% vec) to check if there are 28, 30 or 31 days in that month.\n\n\n\nUse as.Date() to convert the date_2025 as type date.\nCreate a numeric vector housing_price with length 1095 having the value generated from a normal distribution with mean = 10000, sd = 2000.\nCombine date_2025 and housing_price_2025 as a new dataframe housing_2025.\nUse geom_line() with linewidth = 0.3 to plot the average housing price for each date in 2025.",
    "crumbs": [
      "Practices",
      "Week 6 Practices (1007)"
    ]
  },
  {
    "objectID": "practices/wk04.html",
    "href": "practices/wk04.html",
    "title": "Week 4 Practices (0923)",
    "section": "",
    "text": "Remember to use the project you create last week!",
    "crumbs": [
      "Practices",
      "Week 4 Practices (0923)"
    ]
  },
  {
    "objectID": "practices/wk04.html#project",
    "href": "practices/wk04.html#project",
    "title": "Week 4 Practices (0923)",
    "section": "",
    "text": "Remember to use the project you create last week!",
    "crumbs": [
      "Practices",
      "Week 4 Practices (0923)"
    ]
  },
  {
    "objectID": "practices/wk04.html#draw-uniform-random-sample",
    "href": "practices/wk04.html#draw-uniform-random-sample",
    "title": "Week 4 Practices (0923)",
    "section": "2 Draw Uniform Random Sample",
    "text": "2 Draw Uniform Random Sample\nSet random seed as 2025. Draw 200 observations from uniform distribution [0, 100] and compute the mean of the observations.\n\n\n\n\n\n\nTipHint\n\n\n\nHint: Use mean() function.",
    "crumbs": [
      "Practices",
      "Week 4 Practices (0923)"
    ]
  },
  {
    "objectID": "practices/wk04.html#histogram",
    "href": "practices/wk04.html#histogram",
    "title": "Week 4 Practices (0923)",
    "section": "3 Histogram",
    "text": "3 Histogram\n\nUsing the random sample you just generated, create a DataFrame to store the drawn values by using data.frame() function, and draw the histogram graph to see the distribution.\nNow, draw another 10,000 observations from uniform distribution [0, 100], and draw the histogram graph to see the distribution.",
    "crumbs": [
      "Practices",
      "Week 4 Practices (0923)"
    ]
  },
  {
    "objectID": "practices/wk02.html",
    "href": "practices/wk02.html",
    "title": "Week 2 Practices (0909)",
    "section": "",
    "text": "Please download the datasets county.csv and loan50.csv here.",
    "crumbs": [
      "Practices",
      "Week 2 Practices (0909)"
    ]
  },
  {
    "objectID": "practices/wk02.html#download-data",
    "href": "practices/wk02.html#download-data",
    "title": "Week 2 Practices (0909)",
    "section": "",
    "text": "Please download the datasets county.csv and loan50.csv here.",
    "crumbs": [
      "Practices",
      "Week 2 Practices (0909)"
    ]
  },
  {
    "objectID": "practices/wk02.html#import-data",
    "href": "practices/wk02.html#import-data",
    "title": "Week 2 Practices (0909)",
    "section": "2 Import Data",
    "text": "2 Import Data\n\nImport the package tidyverse, which contains several useful functions for data wrangling and visualization.\nCreate a folder on your computer to store the dataset downloaded from NTU COOL or OpenIntro website.\nSet your working directory as that folder and import the datasets county.csv and loan50.csv.",
    "crumbs": [
      "Practices",
      "Week 2 Practices (0909)"
    ]
  },
  {
    "objectID": "practices/wk02.html#scatter-plot",
    "href": "practices/wk02.html#scatter-plot",
    "title": "Week 2 Practices (0909)",
    "section": "3 Scatter Plot",
    "text": "3 Scatter Plot\n\nUse county.csv to draw the scatter plot of unemployment_rate (x-axis) and per_capita_income (y-axis).\n\n\n\n\n\n\n\nTipHint\n\n\n\nHint: You don’t need to specify any parameter in geom_point().\n\n\n\nDraw the same graph again, but this time make the following adjustments:\n\nadjust the point color to lightcoral\nadjust the point size to 0.5",
    "crumbs": [
      "Practices",
      "Week 2 Practices (0909)"
    ]
  },
  {
    "objectID": "practices/wk02.html#histogram",
    "href": "practices/wk02.html#histogram",
    "title": "Week 2 Practices (0909)",
    "section": "4 Histogram",
    "text": "4 Histogram\nUse loan50.csv data to draw the histogram of loan_amount (set as x-axis), and adjust the parameter binwidth in geom_histogram() to 5000.",
    "crumbs": [
      "Practices",
      "Week 2 Practices (0909)"
    ]
  },
  {
    "objectID": "slides/Slides_wk14.html",
    "href": "slides/Slides_wk14.html",
    "title": "Week 14 Slides (1202)",
    "section": "",
    "text": "Open in new tab · Download PDF",
    "crumbs": [
      "Slides",
      "Week 14 Slides (1202)"
    ]
  },
  {
    "objectID": "slides/Slides_wk12.html",
    "href": "slides/Slides_wk12.html",
    "title": "Week 12 Slides (1118)",
    "section": "",
    "text": "Open in new tab · Download PDF",
    "crumbs": [
      "Slides",
      "Week 12 Slides (1118)"
    ]
  },
  {
    "objectID": "slides/Slides_wk10.html",
    "href": "slides/Slides_wk10.html",
    "title": "Week 10 Slides (1104)",
    "section": "",
    "text": "Open in new tab · Download PDF",
    "crumbs": [
      "Slides",
      "Week 10 Slides (1104)"
    ]
  },
  {
    "objectID": "slides/Slides_wk07.html",
    "href": "slides/Slides_wk07.html",
    "title": "Week 7 Slides (1014)",
    "section": "",
    "text": "Open in new tab · Download PDF",
    "crumbs": [
      "Slides",
      "Week 7 Slides (1014)"
    ]
  },
  {
    "objectID": "slides/Slides_wk05.html",
    "href": "slides/Slides_wk05.html",
    "title": "Week 5 Slides (0930)",
    "section": "",
    "text": "Open in new tab · Download PDF",
    "crumbs": [
      "Slides",
      "Week 5 Slides (0930)"
    ]
  },
  {
    "objectID": "slides/Slides_wk03.html",
    "href": "slides/Slides_wk03.html",
    "title": "Week 3 Slides (0916)",
    "section": "",
    "text": "Open in new tab · Download PDF",
    "crumbs": [
      "Slides",
      "Week 3 Slides (0916)"
    ]
  },
  {
    "objectID": "slides/Slides_wk01.html",
    "href": "slides/Slides_wk01.html",
    "title": "Week 1 Slides (0902)",
    "section": "",
    "text": "Open in new tab · Download PDF",
    "crumbs": [
      "Slides",
      "Week 1 Slides (0902)"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "2025Fall Statistics TA Session",
    "section": "",
    "text": "Welcome! Use the sidebar to open weekly Slides, Practices and Answers\nAnswers to the practice will be published after each TA Session.\nSending email: r13323002@ntu.edu.tw (mail title including [Statistics TA])\nTA Office hours: Tuesday, 4:30-5:20 p.m. at SSB. (社會科學院) Room 645.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "slides/Slides_wk02.html",
    "href": "slides/Slides_wk02.html",
    "title": "Week 2 Slides (0909)",
    "section": "",
    "text": "Open in new tab · Download PDF",
    "crumbs": [
      "Slides",
      "Week 2 Slides (0909)"
    ]
  },
  {
    "objectID": "slides/Slides_wk04.html",
    "href": "slides/Slides_wk04.html",
    "title": "Week 4 Slides (0923)",
    "section": "",
    "text": "Open in new tab · Download PDF",
    "crumbs": [
      "Slides",
      "Week 4 Slides (0923)"
    ]
  },
  {
    "objectID": "slides/Slides_wk06.html",
    "href": "slides/Slides_wk06.html",
    "title": "Week 6 Slides (1007)",
    "section": "",
    "text": "Open in new tab · Download PDF",
    "crumbs": [
      "Slides",
      "Week 6 Slides (1007)"
    ]
  },
  {
    "objectID": "slides/Slides_wk09.html",
    "href": "slides/Slides_wk09.html",
    "title": "Week 9 Slides (1028)",
    "section": "",
    "text": "Open in new tab · Download PDF",
    "crumbs": [
      "Slides",
      "Week 9 Slides (1028)"
    ]
  },
  {
    "objectID": "slides/Slides_wk11.html",
    "href": "slides/Slides_wk11.html",
    "title": "Week 11 Slides (1111)",
    "section": "",
    "text": "Open in new tab · Download PDF",
    "crumbs": [
      "Slides",
      "Week 11 Slides (1111)"
    ]
  },
  {
    "objectID": "slides/Slides_wk13.html",
    "href": "slides/Slides_wk13.html",
    "title": "Week 13 Slides (1125)",
    "section": "",
    "text": "Open in new tab · Download PDF",
    "crumbs": [
      "Slides",
      "Week 13 Slides (1125)"
    ]
  },
  {
    "objectID": "practices/wk01.html",
    "href": "practices/wk01.html",
    "title": "Week 1 Practices (0902)",
    "section": "",
    "text": "Create two variables called x and y, and assign values 20250902 and 1031. Compute x / y.",
    "crumbs": [
      "Practices",
      "Week 1 Practices (0902)"
    ]
  },
  {
    "objectID": "practices/wk01.html#assign-values",
    "href": "practices/wk01.html#assign-values",
    "title": "Week 1 Practices (0902)",
    "section": "",
    "text": "Create two variables called x and y, and assign values 20250902 and 1031. Compute x / y.",
    "crumbs": [
      "Practices",
      "Week 1 Practices (0902)"
    ]
  },
  {
    "objectID": "practices/wk01.html#help",
    "href": "practices/wk01.html#help",
    "title": "Week 1 Practices (0902)",
    "section": "2 Help",
    "text": "2 Help\nUse the help() function to check docs, e.g. data.frame() or mean().",
    "crumbs": [
      "Practices",
      "Week 1 Practices (0902)"
    ]
  },
  {
    "objectID": "practices/wk01.html#matrix",
    "href": "practices/wk01.html#matrix",
    "title": "Week 1 Practices (0902)",
    "section": "3 Matrix",
    "text": "3 Matrix\nCreate the following vectors:\nname_vec &lt;- c(\"James\", \"Noc\", \"Monica\")\n\nage_vec &lt;- c(25, 30, 28)\nand create a 3 × 2 matrix with these two vectors.\nDo you encounter errors? Can you print the matrix out? What’s the data type of the matrix?",
    "crumbs": [
      "Practices",
      "Week 1 Practices (0902)"
    ]
  },
  {
    "objectID": "practices/wk03.html",
    "href": "practices/wk03.html",
    "title": "Week 3 Practices (0916)",
    "section": "",
    "text": "Please download the datasets county.csv and loan_full_schema.csv here.",
    "crumbs": [
      "Practices",
      "Week 3 Practices (0916)"
    ]
  },
  {
    "objectID": "practices/wk03.html#download-data",
    "href": "practices/wk03.html#download-data",
    "title": "Week 3 Practices (0916)",
    "section": "",
    "text": "Please download the datasets county.csv and loan_full_schema.csv here.",
    "crumbs": [
      "Practices",
      "Week 3 Practices (0916)"
    ]
  },
  {
    "objectID": "practices/wk03.html#coding-style",
    "href": "practices/wk03.html#coding-style",
    "title": "Week 3 Practices (0916)",
    "section": "2 Coding Style",
    "text": "2 Coding Style\n\nCreate an RStudio project inside a folder with proper names (e.g. TA_Session).\nCreate folders for R scripts and data. (optional: put scripts for the first two weeks’ TA session in the script folder as well.)\nFor the following questions, your code should follow the coding styles in the slides.",
    "crumbs": [
      "Practices",
      "Week 3 Practices (0916)"
    ]
  },
  {
    "objectID": "practices/wk03.html#contingency-table",
    "href": "practices/wk03.html#contingency-table",
    "title": "Week 3 Practices (0916)",
    "section": "3 Contingency Table",
    "text": "3 Contingency Table\nUsing the dataset loans_full_schema.csv, create a contingency table by loan_purpose (set as row) and application_type (set as column), and add the sum row and sum column.",
    "crumbs": [
      "Practices",
      "Week 3 Practices (0916)"
    ]
  },
  {
    "objectID": "practices/wk03.html#bar-graph",
    "href": "practices/wk03.html#bar-graph",
    "title": "Week 3 Practices (0916)",
    "section": "4 Bar Graph",
    "text": "4 Bar Graph\nUsing the dataset loans_full_schema.csv, draw the bar graph to show the numbers of applicant according to each credit grade by following procedures:\n\nSpecify sub_grade as the x-axis, and fill the bar with grade.\nAdd graph title and axis labels\n\nTitle: Number of Applicant by Credit Grade\n\nx-axis: Credit Grade\n\ny-axis: Number of Applicant\n\nCenter the graph title.\n\n\n\n\n\n\n\nTipHint\n\n\n\nHint: Add theme(plot.title = element_text(hjust = 0.5)) to the graph.\n\n\nAfter that, you should have a beautiful graph and share it with me! :)",
    "crumbs": [
      "Practices",
      "Week 3 Practices (0916)"
    ]
  },
  {
    "objectID": "practices/wk05.html",
    "href": "practices/wk05.html",
    "title": "Week 5 Practices (0930)",
    "section": "",
    "text": "Remember to use the project and create a new script in your script folder!\nSet the seed to be 2025.\nBetter to use only the functions taught in the course.",
    "crumbs": [
      "Practices",
      "Week 5 Practices (0930)"
    ]
  },
  {
    "objectID": "practices/wk05.html#reminders",
    "href": "practices/wk05.html#reminders",
    "title": "Week 5 Practices (0930)",
    "section": "",
    "text": "Remember to use the project and create a new script in your script folder!\nSet the seed to be 2025.\nBetter to use only the functions taught in the course.",
    "crumbs": [
      "Practices",
      "Week 5 Practices (0930)"
    ]
  },
  {
    "objectID": "practices/wk05.html#control-flow",
    "href": "practices/wk05.html#control-flow",
    "title": "Week 5 Practices (0930)",
    "section": "2 Control Flow",
    "text": "2 Control Flow\nPrint out the characters \"NTU\" for four times, and then print out the characters \"National Taiwan University\" for six times.\n(There are multiple ways to accomplish this, but I encourage you to use a single for-loop and an if-else statement to complete the task so you can get familiar with these syntax.)",
    "crumbs": [
      "Practices",
      "Week 5 Practices (0930)"
    ]
  },
  {
    "objectID": "practices/wk05.html#binomial-random-sample",
    "href": "practices/wk05.html#binomial-random-sample",
    "title": "Week 5 Practices (0930)",
    "section": "3 Binomial Random Sample",
    "text": "3 Binomial Random Sample\n\nDraw 400 observations from binomial distribution [size = 1000, prob = 0.5] and compute the mean of the observations.\nUsing the random sample you just generated, create a DataFrame to store the drawn values by using data.frame() function, and draw the histogram graph to see the distribution.",
    "crumbs": [
      "Practices",
      "Week 5 Practices (0930)"
    ]
  },
  {
    "objectID": "practices/wk05.html#certification-exam",
    "href": "practices/wk05.html#certification-exam",
    "title": "Week 5 Practices (0930)",
    "section": "4 Certification Exam",
    "text": "4 Certification Exam\nA certification exam is organized for 10 students: Alice, Bob, Charlie, Diana, Ethan, Fiona, George, Hannah, Ivan, and Julia. Each student participates in 10 tests, named test_1, test_2, …, test_10. If the students pass certain amount of tests, they can claim the certificate.\n\nCreate a vector students that contains 10 students’ name.\nCreate a matrix scores that uses the rnorm() to generate students score in 10 tests (average score: 60, standard deviation: 15). Let the column name of the matrix be test_1, test_2, …, test_10.\n\n\n\n\n\n\n\nTipHint\n\n\n\nUse replicate() function to create the matrix first, create a character vector test_names for column names, then use colnames() to assign test_names as the column names of the matrix.\n\n\n\nCreate a dataframe stu_scores that combines students and scores.\n\n\n\n\n\n\n\nTipHint\n\n\n\ndata.frame(name = students, scores) is our new dataframe.\n\n\n\nCreate a function certificate_winner containing three parameters: data, passing_score, min_passed such that a student\n\npasses the test if the his/her score of that test is greater than or equal passing_score\nwins the certificate if the number of passing test is greater than or equal min_passed\n\nFinally, the function should return the students who wins the certificate.\n\n\n\n\n\n\n\nTipHint\n\n\n\nYou can use seq_along in the for-loop, such as for(i in seq_along(data[, 1])){}\n\n\n\n\n\n\n\n\nTipHint\n\n\n\nSet a counter that counts the number of tests the student passed in a for-loop. Remember to reset the counter to be 0 when the next loop begins.\n\n\n\n\n\n\n\n\nTipHint\n\n\n\nCreate a vector passed_students in the function that saves the student’s name if his/her meets the requirements.\n\n\n\nAnswer the following questions:\n\nWho are the certificate winner if passing_score is 60, and the passing_score is 5?\nWho are the certificate winner if passing_score is 65, and the passing_score is 6?",
    "crumbs": [
      "Practices",
      "Week 5 Practices (0930)"
    ]
  },
  {
    "objectID": "practices/wk07.html",
    "href": "practices/wk07.html",
    "title": "Week 7 Practices (1014)",
    "section": "",
    "text": "Remember to use the project and create a new script in your script folder!\nBetter to use only the functions taught in the course.",
    "crumbs": [
      "Practices",
      "Week 7 Practices (1014)"
    ]
  },
  {
    "objectID": "practices/wk07.html#reminders",
    "href": "practices/wk07.html#reminders",
    "title": "Week 7 Practices (1014)",
    "section": "",
    "text": "Remember to use the project and create a new script in your script folder!\nBetter to use only the functions taught in the course.",
    "crumbs": [
      "Practices",
      "Week 7 Practices (1014)"
    ]
  },
  {
    "objectID": "practices/wk07.html#download-data",
    "href": "practices/wk07.html#download-data",
    "title": "Week 7 Practices (1014)",
    "section": "2 Download Data",
    "text": "2 Download Data\nPlease download the datasets loan_full_schema.csv here.",
    "crumbs": [
      "Practices",
      "Week 7 Practices (1014)"
    ]
  },
  {
    "objectID": "practices/wk07.html#wrap-the-graph",
    "href": "practices/wk07.html#wrap-the-graph",
    "title": "Week 7 Practices (1014)",
    "section": "3 Wrap the graph",
    "text": "3 Wrap the graph\nUse the dataset loans_full_schema.csv to create a histogram of the variable interest_rate. Set the bin width to 2.5, and facet the graph by the variable loan_purpose, and allow each sub-graph to have a different y-axis scale.",
    "crumbs": [
      "Practices",
      "Week 7 Practices (1014)"
    ]
  },
  {
    "objectID": "practices/wk07.html#save-the-graph",
    "href": "practices/wk07.html#save-the-graph",
    "title": "Week 7 Practices (1014)",
    "section": "4 Save the graph",
    "text": "4 Save the graph\n\nCreate a folder figures in your project folder.\nSave the graph in the last question to the figures folder with name wk7_default_plot without any customized setting.\nSave another graph with name wk7_sized_plot using height = 6, width = 4.\nAdd assignment dpi = 150 to the last graph, and named the new graph as wk7_sized_plot_150dpi.\nCompare the differences between wk7_default_plot, wk7_sized_plot and wk7_sized_plot_150dpi.",
    "crumbs": [
      "Practices",
      "Week 7 Practices (1014)"
    ]
  },
  {
    "objectID": "practices/wk10.html",
    "href": "practices/wk10.html",
    "title": "Week 10 Practices (1104)",
    "section": "",
    "text": "Remember to use the project and create a new script in your script folder!\nBetter to use only the functions taught in the course.",
    "crumbs": [
      "Practices",
      "Week 10 Practices (1104)"
    ]
  },
  {
    "objectID": "practices/wk10.html#reminders",
    "href": "practices/wk10.html#reminders",
    "title": "Week 10 Practices (1104)",
    "section": "",
    "text": "Remember to use the project and create a new script in your script folder!\nBetter to use only the functions taught in the course.",
    "crumbs": [
      "Practices",
      "Week 10 Practices (1104)"
    ]
  },
  {
    "objectID": "practices/wk10.html#clt-simulation",
    "href": "practices/wk10.html#clt-simulation",
    "title": "Week 10 Practices (1104)",
    "section": "2 CLT Simulation",
    "text": "2 CLT Simulation\n\n2.1 Draw Poisson Sample\nWrite a function called sample_mean_pois(n) with the following specification:\n\nDraw \\(n\\) random samples from a Poisson distribution \\(\\lambda = 5\\).\n\n2.Compute the sample mean.\n\nReturn the sample mean.\n\nThis function allows you to draw \\(n\\) random samples from a Poisson distribution (\\(\\lambda=5\\)) and compute the sample mean.\n\n\n2.2 Build Sample Mean DataFrame\nNow, we’re going to utilize the function to help us compute the sample mean multiple times. Please follow the instructions step-by-step:\n\nSet the random seed to 2025.\nGiven \\(n=500\\), use the function replicate() to execute the function sample_mean_pois(n) we just defined for 1,000 times.\nAfter that, you should obtain 1,000 sample means. Assign the 1,000 sample means to a variable called rdmean and build a DataFrame from it.\n\nSo far, we have obtained \\(1,000\\) sample means, each calculated from \\(500\\) Poisson samples.\n\n\n2.3 Histogram\nUsing the DataFrame we just built, draw a histogram to examine the distribution of the sample means.",
    "crumbs": [
      "Practices",
      "Week 10 Practices (1104)"
    ]
  },
  {
    "objectID": "practices/wk12.html",
    "href": "practices/wk12.html",
    "title": "Week 12 Practices (1118)",
    "section": "",
    "text": "Remember to use the project and create a new script in your script folder!\nBetter to use only the functions taught in the course.",
    "crumbs": [
      "Practices",
      "Week 12 Practices (1118)"
    ]
  },
  {
    "objectID": "practices/wk12.html#reminders",
    "href": "practices/wk12.html#reminders",
    "title": "Week 12 Practices (1118)",
    "section": "",
    "text": "Remember to use the project and create a new script in your script folder!\nBetter to use only the functions taught in the course.",
    "crumbs": [
      "Practices",
      "Week 12 Practices (1118)"
    ]
  },
  {
    "objectID": "practices/wk12.html#download-data",
    "href": "practices/wk12.html#download-data",
    "title": "Week 12 Practices (1118)",
    "section": "2 Download Data",
    "text": "2 Download Data\nPlease download the datasets transactions.csv (right click here)",
    "crumbs": [
      "Practices",
      "Week 12 Practices (1118)"
    ]
  },
  {
    "objectID": "practices/wk12.html#silent-witch-chinmoku-no-majo-no-kakushigoto-silent-witch-沉默魔女的祕密",
    "href": "practices/wk12.html#silent-witch-chinmoku-no-majo-no-kakushigoto-silent-witch-沉默魔女的祕密",
    "title": "Week 12 Practices (1118)",
    "section": "3 Silent Witch: Chinmoku no Majo no Kakushigoto (Silent Witch 沉默魔女的祕密)",
    "text": "3 Silent Witch: Chinmoku no Majo no Kakushigoto (Silent Witch 沉默魔女的祕密)\nMonica is the new accountant for the Serendia Academy’s student association. She suspects that cash vs non-cash transactions in 2024 look quite different from previous years, and worries there might be some false accounting going on.\nMonica sees a dataset transactions.csv with the following columns:\n\nyear: the year of the transaction (2015–2024)\n\npayment_type: \"cash\", \"bank_transfer\", or \"online\"\n\namount: transaction amount in dollars\n\nShe wants to use a chi-squared test to check if the distribution of payment types in 2024’s accounting is significantly different from the other years.\n\nUse the pipe %&gt;% in the steps below.\nCreate a new column period with two categories: pre_2024 for years 2015–2023, year_2024 for year 2024 only. Save the result as transactions_by2024.\nUsing group_by() and summarise(), compute a table of the number and mean of transactions for each combination of period and payment_type from transactions_by2024.\nFrom transactions_by2024, create a 2 × 3 contingency table tab (period × payment_type) using table().\nUse chisq.test() on tab to test:\n\n\\(H_0\\): The distribution of payment_type is the same in pre_2024 and year_2024.\n\\(H_1\\): The distribution of payment_type is different in year_2024.\n\nReport the p-value from the chi-squared test. Is there false accounting in 2024?",
    "crumbs": [
      "Practices",
      "Week 12 Practices (1118)"
    ]
  },
  {
    "objectID": "practices/wk14.html",
    "href": "practices/wk14.html",
    "title": "Week 14 Practices (1202)",
    "section": "",
    "text": "Remember to use the project and create a new script in your script folder!\nBetter to use only the functions taught in the course.",
    "crumbs": [
      "Practices",
      "Week 14 Practices (1202)"
    ]
  },
  {
    "objectID": "practices/wk14.html#reminders",
    "href": "practices/wk14.html#reminders",
    "title": "Week 14 Practices (1202)",
    "section": "",
    "text": "Remember to use the project and create a new script in your script folder!\nBetter to use only the functions taught in the course.",
    "crumbs": [
      "Practices",
      "Week 14 Practices (1202)"
    ]
  },
  {
    "objectID": "practices/wk14.html#download-data",
    "href": "practices/wk14.html#download-data",
    "title": "Week 14 Practices (1202)",
    "section": "2 Download Data",
    "text": "2 Download Data\nPlease download the datasets nba_players_19.csv and gpa_iq.csv here.",
    "crumbs": [
      "Practices",
      "Week 14 Practices (1202)"
    ]
  },
  {
    "objectID": "practices/wk14.html#anova",
    "href": "practices/wk14.html#anova",
    "title": "Week 14 Practices (1202)",
    "section": "3 ANOVA",
    "text": "3 ANOVA\n\n3.1 ANOVA Testing\nUse the aov() function to perform an ANOVA test to determine if there is no difference in height among players in each position group. Then, use the summary() function to obtain the p-value and make a conclusion.",
    "crumbs": [
      "Practices",
      "Week 14 Practices (1202)"
    ]
  },
  {
    "objectID": "practices/wk14.html#linear-regression",
    "href": "practices/wk14.html#linear-regression",
    "title": "Week 14 Practices (1202)",
    "section": "4 Linear Regression",
    "text": "4 Linear Regression\n\n4.1 Correlation Coefficient\nUsing the gpa dataset, use the summarize() function to compute the standard deviation of gpa, the standard deviation of iq, and the correlation coefficient between gpa and iq.\n\n\n\n\n\n\nTipHint\n\n\n\nUse cor(x, y) to compute the correlation coefficient between the variables x and y.\n\n\n\n\n4.2 Regression\nNow suppose gpa is the outcome (dependent variable), and iq is the explanatory (independent variable). Use the lm() function to predict gpa based on iq. In other words, fit a linear model to estimate the relationship between gpa and iq.\n\n\n4.3 Regression with Plot\nLastly, let’s visualize the linear regression on a scatter plot. Create the plot with the following specifications:\n\nUse the ggplot() and geom_point() function to create a scatter plot, with the x-axis representing iq and the y-axis representing gpa.\nUse the geom_smooth() function to add a fitted line based on a linear model.",
    "crumbs": [
      "Practices",
      "Week 14 Practices (1202)"
    ]
  },
  {
    "objectID": "answers/wk02_answer.html",
    "href": "answers/wk02_answer.html",
    "title": "Week 2 Answers (0909)",
    "section": "",
    "text": "Please download the datasets county.csv and loan50.csv here.",
    "crumbs": [
      "Practice Answers",
      "Week 2 Answers (0909)"
    ]
  },
  {
    "objectID": "answers/wk02_answer.html#download-data",
    "href": "answers/wk02_answer.html#download-data",
    "title": "Week 2 Answers (0909)",
    "section": "",
    "text": "Please download the datasets county.csv and loan50.csv here.",
    "crumbs": [
      "Practice Answers",
      "Week 2 Answers (0909)"
    ]
  },
  {
    "objectID": "answers/wk02_answer.html#import-data",
    "href": "answers/wk02_answer.html#import-data",
    "title": "Week 2 Answers (0909)",
    "section": "2 Import Data",
    "text": "2 Import Data\n\nImport the package tidyverse, which contains several useful functions for data wrangling and visualization.\nCreate a folder on your computer to store the dataset downloaded from NTU COOL or OpenIntro website.\nSet your working directory as that folder and import the datasets county.csv and loan50.csv.\n\nlibrary(tidyverse)\nsetwd(\"/your/working/directory\")\ncounty &lt;- read.csv(\"county.csv\")\nloan &lt;- read.csv(\"loan50.csv\")",
    "crumbs": [
      "Practice Answers",
      "Week 2 Answers (0909)"
    ]
  },
  {
    "objectID": "answers/wk02_answer.html#scatter-plot",
    "href": "answers/wk02_answer.html#scatter-plot",
    "title": "Week 2 Answers (0909)",
    "section": "3 Scatter Plot",
    "text": "3 Scatter Plot\n\nUse county.csv to draw the scatter plot of unemployment_rate (x-axis) and per_capita_income (y-axis).\n\n\n\n\n\n\n\nTipHint\n\n\n\nHint: You don’t need to specify any parameter in geom_point().\n\n\nggplot(county, aes(x = unemployment_rate, y = per_capita_income)) + \n  geom_point()\n\n\n\n\n\n\n\n\n\n\nDraw the same graph again, but this time make the following adjustments:\n\nadjust the point color to lightcoral\nadjust the point size to 0.5\n\n\nggplot(county, aes(x = unemployment_rate, y = per_capita_income)) +\n  geom_point(color = \"lightcoral\", size = 0.5)",
    "crumbs": [
      "Practice Answers",
      "Week 2 Answers (0909)"
    ]
  },
  {
    "objectID": "answers/wk02_answer.html#histogram",
    "href": "answers/wk02_answer.html#histogram",
    "title": "Week 2 Answers (0909)",
    "section": "4 Histogram",
    "text": "4 Histogram\nUse loan50.csv data to draw the histogram of loan_amount (set as x-axis), and adjust the parameter binwidth in geom_histogram() to 5000.\nggplot(loan, aes(x = loan_amount)) +\n  geom_histogram(binwidth = 5000)",
    "crumbs": [
      "Practice Answers",
      "Week 2 Answers (0909)"
    ]
  },
  {
    "objectID": "answers/wk04_answer.html",
    "href": "answers/wk04_answer.html",
    "title": "Week 4 Answers (0923)",
    "section": "",
    "text": "Remember to use the project you create last week!",
    "crumbs": [
      "Practice Answers",
      "Week 4 Answers (0923)"
    ]
  },
  {
    "objectID": "answers/wk04_answer.html#project",
    "href": "answers/wk04_answer.html#project",
    "title": "Week 4 Answers (0923)",
    "section": "",
    "text": "Remember to use the project you create last week!",
    "crumbs": [
      "Practice Answers",
      "Week 4 Answers (0923)"
    ]
  },
  {
    "objectID": "answers/wk04_answer.html#draw-uniform-random-sample",
    "href": "answers/wk04_answer.html#draw-uniform-random-sample",
    "title": "Week 4 Answers (0923)",
    "section": "2 Draw Uniform Random Sample",
    "text": "2 Draw Uniform Random Sample\nSet random seed as 2025. Draw 200 observations from uniform distribution [0, 100] and compute the mean of the observations.\n\n\n\n\n\n\nTipHint\n\n\n\nHint: Use mean() function.\n\n\nset.seed(2025)\nsample_size &lt;- 200\nrdn &lt;- runif(n = sample_size, min = 0, max = 100)\nmean &lt;- mean(rdn)\nprint(mean)\n## [1] 52.17858",
    "crumbs": [
      "Practice Answers",
      "Week 4 Answers (0923)"
    ]
  },
  {
    "objectID": "answers/wk04_answer.html#histogram",
    "href": "answers/wk04_answer.html#histogram",
    "title": "Week 4 Answers (0923)",
    "section": "3 Histogram",
    "text": "3 Histogram\n\nUsing the random sample you just generated, create a DataFrame to store the drawn values by using data.frame() function, and draw the histogram graph to see the distribution.\n\ndf_1 &lt;- data.frame(\n  values = rdn\n)\nggplot(df_1, aes(x = values)) +\n  geom_histogram()\n\n\n\n\n\n\n\n\n\n\nNow, draw another 10,000 observations from uniform distribution [0, 100], and draw the histogram graph to see the distribution.\n\nrdn_2 &lt;- runif(n = 10000, min = 0, max = 100)\ndf_2 &lt;- data.frame(\n  values = rdn_2\n)\nggplot(df_2, aes(x = values)) +\n  geom_histogram()",
    "crumbs": [
      "Practice Answers",
      "Week 4 Answers (0923)"
    ]
  },
  {
    "objectID": "answers/wk06_answer.html",
    "href": "answers/wk06_answer.html",
    "title": "Week 6 Practices (1007)",
    "section": "",
    "text": "Remember to use the project and create a new script in your script folder!\nSet the seed to be 2025.\nBetter to use only the functions taught in the course.",
    "crumbs": [
      "Practice Answers",
      "Week 6 Practices (1007)"
    ]
  },
  {
    "objectID": "answers/wk06_answer.html#reminders",
    "href": "answers/wk06_answer.html#reminders",
    "title": "Week 6 Practices (1007)",
    "section": "",
    "text": "Remember to use the project and create a new script in your script folder!\nSet the seed to be 2025.\nBetter to use only the functions taught in the course.",
    "crumbs": [
      "Practice Answers",
      "Week 6 Practices (1007)"
    ]
  },
  {
    "objectID": "answers/wk06_answer.html#download-data",
    "href": "answers/wk06_answer.html#download-data",
    "title": "Week 6 Practices (1007)",
    "section": "2 Download Data",
    "text": "2 Download Data\nPlease download the datasets ames.csv here.",
    "crumbs": [
      "Practice Answers",
      "Week 6 Practices (1007)"
    ]
  },
  {
    "objectID": "answers/wk06_answer.html#housing-price-in-2025",
    "href": "answers/wk06_answer.html#housing-price-in-2025",
    "title": "Week 6 Practices (1007)",
    "section": "3 Housing Price in 2025",
    "text": "3 Housing Price in 2025\n\nUse paste() and for-loop to create a character vector date_2025 that contains 365 days in 2025, and each date repeat 3 times. i.e., c(\"2025-01-01\", \"2025-01-01\", \"2025-01-01\", ..., \"2025-12-31\")\n\n\n\n\n\n\n\nTipHint\n\n\n\nUse if (month %in% vec) to check if there are 28, 30 or 31 days in that month.\n\n\n\nUse as.Date() to convert the date_2025 as type date.\nCreate a numeric vector housing_price with length 1095 having the value generated from a normal distribution with mean = 10000, sd = 2000.\nCombine date_2025 and housing_price_2025 as a new dataframe housing_2025.\nUse geom_line() with linewidth = 0.3 to plot the average housing price for each date in 2025.\n\nset.seed(2025)\n\nlibrary(tidyverse)\n\ndate_2025 &lt;- c()\n\nfor (month in 1:12){\n  if (month %in% c(1, 3, 5, 7, 8, 10, 12)){\n    for (day in 1:31){\n      temp &lt;- replicate(n = 3, expr = paste(\"2025\", month, day, \n                                            sep = \"-\")\n                        )\n      date_2025 &lt;- c(date_2025, temp)\n    }\n  }\n  else if (month %in% c(4, 6, 9, 11)){\n    for (day in 1:30){\n      temp &lt;- replicate(n = 3, expr = paste(\"2025\", month, day, \n                                            sep = \"-\")\n                        )\n      date_2025 &lt;- c(date_2025, temp)\n    }    \n  }\n  else{\n    for (day in 1:28){\n      temp &lt;- replicate(n = 3, expr = paste(\"2025\", \"2\", day, \n                                            sep = \"-\")\n                        )\n      date_2025 &lt;- c(date_2025, temp)\n    }        \n  }\n}\n\ndate_2025 &lt;- as.Date(date_2025)\n\nhousing_price_2025 &lt;- rnorm(n = 1095, mean = 10000, sd = 2000)\n\nhousing_2025 &lt;- data.frame(date = date_2025,\n                           price = housing_price_2025\n                           )\n\nggplot(housing_2025, aes(x = date, y = price)) + \n    geom_line(stat = \"summary\", \n              fun = \"mean\", \n              linewidth = 0.3, \n              color = \"steelblue\"\n              )",
    "crumbs": [
      "Practice Answers",
      "Week 6 Practices (1007)"
    ]
  },
  {
    "objectID": "answers/wk09_answer.html",
    "href": "answers/wk09_answer.html",
    "title": "Week 9 Answers (1028)",
    "section": "",
    "text": "Remember to use the project and create a new script in your script folder!\nBetter to use only the functions taught in the course.",
    "crumbs": [
      "Practice Answers",
      "Week 9 Answers (1028)"
    ]
  },
  {
    "objectID": "answers/wk09_answer.html#reminders",
    "href": "answers/wk09_answer.html#reminders",
    "title": "Week 9 Answers (1028)",
    "section": "",
    "text": "Remember to use the project and create a new script in your script folder!\nBetter to use only the functions taught in the course.",
    "crumbs": [
      "Practice Answers",
      "Week 9 Answers (1028)"
    ]
  },
  {
    "objectID": "answers/wk09_answer.html#download-data",
    "href": "answers/wk09_answer.html#download-data",
    "title": "Week 9 Answers (1028)",
    "section": "2 Download Data",
    "text": "2 Download Data\nPlease download the datasets restaurants.csv (right click here)",
    "crumbs": [
      "Practice Answers",
      "Week 9 Answers (1028)"
    ]
  },
  {
    "objectID": "answers/wk09_answer.html#nohara-hiroshi-hiru-meshi-no-ryuugi-野原廣志-午餐的流派",
    "href": "answers/wk09_answer.html#nohara-hiroshi-hiru-meshi-no-ryuugi-野原廣志-午餐的流派",
    "title": "Week 9 Answers (1028)",
    "section": "3 Nohara Hiroshi: Hiru Meshi no Ryuugi (野原廣志 午餐的流派)",
    "text": "3 Nohara Hiroshi: Hiru Meshi no Ryuugi (野原廣志 午餐的流派)\n“My name is Hiroshi Nohara (野原廣志). I’m an office worker and often eat lunch out. Based on the state of my body and my wallet, I quickly decide what to eat each day. You could say that while I’m a business expert, I’m also a lunch expert.”\nHiroshi keeps a list of restaurants in restaurants.csv. The file has five columns:\n\nname: The restaurant’s name.\ntype: The type of cuisine.\nclosed: The restaurant’s closed day; some restaurants are permanently closed.\nlunch_set: Whether the restaurant offers lunch sets at noon.\nrating: Hiroshi’s personal rating for the restaurant.\n\nToday is Thursday. Hiroshi feels like seafood, but curry or noodles would also be fine. Since he had fast food yesterday, he’d rather avoid it today. It’s close to the end of the month, so it would be better if the restaurant offers lunch sets.\nFollow the instructions below to help Hiroshi choose the restaurants that best fit his needs:\n\n\n\n\n\n\nTipHint\n\n\n\nIn this practice, filter(), select(), mutate(), arrange() will all be used.\n\n\n\nUse the pipe %&gt;% in the steps below.\nFilter the restaurants that are open today.\nAdd a column lunch_set_score that is 1.5 if the restaurant offers lunch sets and 0 otherwise.\nAdd a column preference_score that takes value 1.5 for seafood, 1 for curry and noodle, -2 for fastfood, and 0 otherwise.\nAdd a column total_score that sums up the columns rating, lunch_set_score and preference_score.\nRemove the lunch_set_score and preference_score columns.\nArrange the rows in descending order of total_score.\nPrint the top 5 rows with the highest total_score.\n\nlibrary(tidyverse)\n\nrestaurants &lt;- read.csv(\"data/restaurants.csv\")\n\nrestaurants_cleaned &lt;- restaurants %&gt;% \n  filter(closed != \"Thu\" & closed != \"close down\") %&gt;%\n  mutate(lunch_set_score = ifelse(lunch_set == \"Yes\", 1.5, 0)) %&gt;%\n  mutate(preference_score = case_when(\n    type == \"seafood\" ~ 1.5,\n    type == \"curry\" | type == \"noodle\" ~ 1,\n    type == \"fastfood\" ~ -2,\n    TRUE ~ 0\n    )) %&gt;%\n  mutate(total_score = rating + lunch_set_score + preference_score) %&gt;%\n  select(-c(lunch_set_score, preference_score)) %&gt;%\n  arrange(desc(total_score))\n  \nprint(restaurants_cleaned[1:5, ])\n#### Answers\n##               name    type closed lunch_set rating total_score\n## 1       Curry Spot   curry    Fri       Yes    4.4         6.9\n## 2    Curry Delight   curry    Sun       Yes    3.9         6.4\n## 3 Blue Ocean Grill seafood    Fri        No    4.2         5.7\n## 4   Mama’s Kitchen   other    Fri       Yes    4.1         5.6\n## 5      Urban Pizza   pizza    Sun       Yes    4.0         5.5",
    "crumbs": [
      "Practice Answers",
      "Week 9 Answers (1028)"
    ]
  },
  {
    "objectID": "answers/wk11_answer.html",
    "href": "answers/wk11_answer.html",
    "title": "Week 11 Answers (1111)",
    "section": "",
    "text": "Remember to use the project and create a new script in your script folder!\nBetter to use only the functions taught in the course.",
    "crumbs": [
      "Practice Answers",
      "Week 11 Answers (1111)"
    ]
  },
  {
    "objectID": "answers/wk11_answer.html#reminders",
    "href": "answers/wk11_answer.html#reminders",
    "title": "Week 11 Answers (1111)",
    "section": "",
    "text": "Remember to use the project and create a new script in your script folder!\nBetter to use only the functions taught in the course.",
    "crumbs": [
      "Practice Answers",
      "Week 11 Answers (1111)"
    ]
  },
  {
    "objectID": "answers/wk11_answer.html#download-data",
    "href": "answers/wk11_answer.html#download-data",
    "title": "Week 11 Answers (1111)",
    "section": "2 Download Data",
    "text": "2 Download Data\nPlease download the datasets garden_shifts.csv (right click here)",
    "crumbs": [
      "Practice Answers",
      "Week 11 Answers (1111)"
    ]
  },
  {
    "objectID": "answers/wk11_answer.html#isekai-nonbiri-nouka-異世界悠閒農家",
    "href": "answers/wk11_answer.html#isekai-nonbiri-nouka-異世界悠閒農家",
    "title": "Week 11 Answers (1111)",
    "section": "3 Isekai Nonbiri Nouka (異世界悠閒農家)",
    "text": "3 Isekai Nonbiri Nouka (異世界悠閒農家)\nHiraku is the village head of Taiju no mura (大樹村) and owns a big farmland. He keeps a log of when each villager — Hiraku, Rurushi, Tia, Ria, Daga, Fraurem, Senna — is responsible for a plot. However, because the log was kept by hand and then typed in, the dates are a bit messy and some entries are incomplete.\nHiraku sees a dataset garden_shifts.csv with the following columns:\n\nname: villager name\nstart_str: start date of the shift\n\nend_str: end date of the shift\nplot: which plant/plot they look after\n\nAll shifts are in September and October 2025, and no villager works on more than one plot on the same day.\nHiraku wants to know how many days each villager works in October.\n\nUse the pipe %&gt;% in the steps below.\nCreate a new data frame shifts_complete that adds two new columns, start_date and end_date, which convert start_str and end_date to Date types for the original data.\n\n\n\n\n\n\n\nTipHint\n\n\n\nRemember to keep NA as NA when using mutate().\n\n\n\n\n\n\n\n\nTipHint\n\n\n\nUse grepl(\"-\", start_str) ~ in case_when().\n\n\n\nDrops any rows containing NA (in any column) in shifts_complete .\nCreate a new data frame shifts_coverage that includes the full sequence of dates from start_date to end_date in shifts_coverage.\n\n\n\n\n\n\n\nTipHint\n\n\n\nFor example, if Hiraku is responsible for cabbage from 2025-09-10 to 2025-09-13, then there would be 4 rows that take value 2025-09-10, 2025-09-11, 2025-09-12 and 2025-09-13 in column date for shifts_complete.\n\n\n\n\n\n\n\n\nTipHint\n\n\n\nFor each row in shifts_complete, create a temperate data frame temp in the for-loop with columns name, plot, date, where date columns includes all the dates between start_date and end_date.\n\n\n\n\n\n\n\n\nTipHint\n\n\n\nUse rbind() to combine data frames in each loop.\n\n\n\nAdd a column month to shifts_coverage that contains only the YYYY-MM part of column date.\nCreate a new data frame shifts_coverage_oct for dates in October only.\nHow many days does each villager work in October?\n\nlibrary(tidyverse)\n\nshifts &lt;- read.csv(\"data/garden_shifts.csv\")\n\n# Part 1\nshifts_complete &lt;- shifts %&gt;%\n  mutate(\n    start_date = case_when(\n      grepl(\"-\", start_str) ~ as.Date(start_str, format = \"%Y-%m-%d\"),\n      grepl(\"/\", start_str) ~ as.Date(start_str, format = \"%Y/%m/%d\"),\n      TRUE ~ NA\n      )\n    ) %&gt;% \n  mutate(\n    end_date = case_when(\n      grepl(\"-\", end_str) ~ as.Date(end_str, format = \"%Y-%m-%d\"),\n      grepl(\"/\", end_str) ~ as.Date(end_str, format = \"%Y/%m/%d\"),\n      TRUE ~ NA\n      )\n    )\n\n# Part 2 \nshifts_complete &lt;- shifts_complete %&gt;% \n  na.omit()\n\n# Part 3\nfor(i in seq_along(shifts_complete$name)){\n  days &lt;- seq(from = shifts_complete$start_date[i],\n              to = shifts_complete$end_date[i],\n              by = \"day\")\n  \n  temp &lt;- data.frame(\n    name = shifts_complete$name[i],\n    plot = shifts_complete$plot[i],\n    date = days\n  )\n  if(i == 1){\n    shifts_coverage &lt;- temp\n  }\n  else{\n    shifts_coverage &lt;- rbind(shifts_coverage, temp)\n  }\n}\n\n# Part 4\nshifts_coverage &lt;- shifts_coverage %&gt;% \n  mutate(month = substring(date, 1, 7))\n\n# Part 5\nshifts_coverage_oct &lt;- shifts_coverage %&gt;%\n  filter(month == \"2025-10\")\n\n# Part 6\nvillagers &lt;- c(\"Hiraku\", \"Rurushi\", \"Tia\", \"Ria\", \"Daga\", \"Fraurem\", \"Senna\")\ndays_vec &lt;- c()\n\nfor(villager in villagers){\n  temp &lt;- shifts_coverage_oct %&gt;% \n    filter(name == villager)\n  days_vec &lt;- c(days_vec, nrow(temp))\n}\n\nvillager_oct_days &lt;- data.frame(\n  name = villagers,\n  num_days = days_vec\n)\n\nprint(villager_oct_days)\n\n\n     name num_days\n1  Hiraku       22\n2 Rurushi       10\n3     Tia       21\n4     Ria       18\n5    Daga       20\n6 Fraurem       20\n7   Senna       19",
    "crumbs": [
      "Practice Answers",
      "Week 11 Answers (1111)"
    ]
  },
  {
    "objectID": "answers/wk13_answer.html",
    "href": "answers/wk13_answer.html",
    "title": "Week 13 Answers (1125)",
    "section": "",
    "text": "Remember to use the project and create a new script in your script folder!\nBetter to use only the functions taught in the course.",
    "crumbs": [
      "Practice Answers",
      "Week 13 Answers (1125)"
    ]
  },
  {
    "objectID": "answers/wk13_answer.html#reminders",
    "href": "answers/wk13_answer.html#reminders",
    "title": "Week 13 Answers (1125)",
    "section": "",
    "text": "Remember to use the project and create a new script in your script folder!\nBetter to use only the functions taught in the course.",
    "crumbs": [
      "Practice Answers",
      "Week 13 Answers (1125)"
    ]
  },
  {
    "objectID": "answers/wk13_answer.html#shangri-la-frontier-香格里拉開拓異境",
    "href": "answers/wk13_answer.html#shangri-la-frontier-香格里拉開拓異境",
    "title": "Week 13 Answers (1125)",
    "section": "2 Shangri-La Frontier (香格里拉·開拓異境)",
    "text": "2 Shangri-La Frontier (香格里拉·開拓異境)\nShangri-La Frontier is a cutting-edge VRMMO game. After a major update, Sunraku is testing a new build and wants to know whether it actually increases his average damage per combo compared to his old build, which had a known average of 1200 damage per combo in similar areas.\nSunraku goes to a stable grinding spot and records the damage per combo for 15 battles using the new build:\n\\[\n1310, 1195, 1240, 1285, 1220,\n1350, 1290, 1210, 1265, 1305,\n1330, 1275, 1255, 1190, 1320\n\\]\n\nRun an appropriate one-sample t-test using t.test(), and report a 95% confidence interval for the mean damage with the form: 95 percent confidence interval: (a, b).\n\ndamage_sunraku &lt;- c(\n  1310, 1195, 1240, 1285, 1220,\n  1350, 1290, 1210, 1265, 1305,\n  1330, 1275, 1255, 1190, 1320\n)\n\n# Test if mean &gt; 1200\nt.test(\n  damage_sunraku,\n  mu = 1200,\n  alternative = \"greater\",\n  conf.level = 0.95\n)\n\nprint(paste0(\"95 percent confidence interval:(\",\n             test_1$conf.int[1], \n             \" \", \n             test_1$conf.int[2], \n             \")\"\n             )\n      )\n\n# (Optional) you can also run a two-sided test\nt.test(\n  damage_sunraku,\n  mu = 1200,\n  alternative = \"two.sided\",\n  conf.level = 0.95\n)\n\n\n\n    One Sample t-test\n\ndata:  damage_sunraku\nt = 5.352, df = 14, p-value = 5.105e-05\nalternative hypothesis: true mean is greater than 1200\n95 percent confidence interval:\n 1246.516      Inf\nsample estimates:\nmean of x \n 1269.333 \n\n\n[1] \"95 percent confidence interval:(1246.51601109891 Inf)\"\n\n\nPsyger-0 is another top-tier player in Shangri-La Frontier, known for her insane burst damage. She tests her own optimized build in the same area and logs her damage per combo in 12 battles:\n\\[\n1380, 1425, 1405, 1360, 1390,\n1435, 1410, 1375, 1440, 1400,\n1395, 1420\n\\]\n\nDoes Psyger-0’s build have a different mean damage than Sunraku’s new build? Report the p-value.\n\ndamage_psyger0 &lt;- c(\n  1380, 1425, 1405, 1360, 1390,\n  1435, 1410, 1375, 1440, 1400,\n  1395, 1420\n)\n\n# Test if their damage if different\nt.test(\n  damage_sunraku,\n  damage_psyger0,\n  alternative = \"two.sided\",\n  conf.level = 0.95\n)\n\n\n\n    Welch Two Sample t-test\n\ndata:  damage_sunraku and damage_psyger0\nt = -9.0474, df = 21.21, p-value = 9.95e-09\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -164.2699 -102.8967\nsample estimates:\nmean of x mean of y \n 1269.333  1402.917 \n\n\n[1] 9.949658e-09",
    "crumbs": [
      "Practice Answers",
      "Week 13 Answers (1125)"
    ]
  },
  {
    "objectID": "example_code/Example_Code_wk02.html",
    "href": "example_code/Example_Code_wk02.html",
    "title": "Week 2 Example R Code (0909)",
    "section": "",
    "text": "Right click to download:\n\nwk2_example_code.R",
    "crumbs": [
      "Example R code",
      "Week 2 Example R Code (0909)"
    ]
  },
  {
    "objectID": "example_code/Example_Code_wk04.html",
    "href": "example_code/Example_Code_wk04.html",
    "title": "Week 4 Example R Code (0923)",
    "section": "",
    "text": "Right click to download:\n\nwk4_example_code.R",
    "crumbs": [
      "Example R code",
      "Week 4 Example R Code (0923)"
    ]
  },
  {
    "objectID": "example_code/Example_Code_wk06.html",
    "href": "example_code/Example_Code_wk06.html",
    "title": "Week 6 Example R Code (1007)",
    "section": "",
    "text": "Right click to download:\n\nwk6_example_code.R",
    "crumbs": [
      "Example R code",
      "Week 6 Example R Code (1007)"
    ]
  },
  {
    "objectID": "example_code/Example_Code_wk09.html",
    "href": "example_code/Example_Code_wk09.html",
    "title": "Week 9 Example R Code (1028)",
    "section": "",
    "text": "Right click to download:\n\nwk9_example_code.R",
    "crumbs": [
      "Example R code",
      "Week 9 Example R Code (1028)"
    ]
  },
  {
    "objectID": "example_code/Example_Code_wk11.html",
    "href": "example_code/Example_Code_wk11.html",
    "title": "Week 11 Example R Code (1111)",
    "section": "",
    "text": "Right click to download:\n\nwk11_example_code.R",
    "crumbs": [
      "Example R code",
      "Week 11 Example R Code (1111)"
    ]
  },
  {
    "objectID": "example_code/Example_Code_wk13.html",
    "href": "example_code/Example_Code_wk13.html",
    "title": "Week 13 Example R Code (1125)",
    "section": "",
    "text": "Right click to download:\n\nwk13_example_code.R",
    "crumbs": [
      "Example R code",
      "Week 13 Example R Code (1125)"
    ]
  },
  {
    "objectID": "homework/hw1_answer.html",
    "href": "homework/hw1_answer.html",
    "title": "Homework 1 Answers",
    "section": "",
    "text": "If you find any typos or errors, please feel free to contact me via email at r13323002@ntu.edu.tw. I would appreciate it and will correct the solution to prevent any misunderstandings.\nFor some R commands marked with ‘OPTIONAL,’ you don’t need to learn them. You will be completely fine on the computer quiz even if you choose to ignore them.\nIf you’re having trouble understanding the code, don’t hesitate to ask me for help. I’ll do my best to assist you during office hours or after the TA session.",
    "crumbs": [
      "Homework Solutions",
      "Homework 1 Answers"
    ]
  },
  {
    "objectID": "homework/hw1_answer.html#computer-exercises",
    "href": "homework/hw1_answer.html#computer-exercises",
    "title": "Homework 1 Answers",
    "section": "1 Computer Exercises",
    "text": "1 Computer Exercises\n\n1.1 Figure 1.8: Scatter Plot\n# draw the scatter plot \nscatter_plot_1 &lt;- ggplot(county, aes(x = multi_unit, y = homeownership)) +\n  \n  ## adjust the points\n  geom_point(color = \"steelblue\", fill = \"black\", shape = 21, stroke = 0.9) +\n  \n  ## add labels and graph title to make the graph readable\n  labs(\n    x = \"Percent of Units in Multi-Unit Structures\",\n    y = \"Homeownership Rate\",\n    title = \"Figure 1.8: Homeownership vs. Multi-Unit Structures\"\n  ) +\n  \n  ## center the title text\n  theme(plot.title = element_text(hjust = 0.5)) +\n  \n  ## adjust the scale of x, y-axis\n  scale_x_continuous(\n    breaks = c(0, 20, 40, 60, 80, 100),\n    labels = c(\"0%\", \"20%\", \"40%\", \"60%\", \"80%\", \"100%\")\n  ) +\n  scale_x_continuous(\n    breaks = c(0, 20, 40, 60, 80, 100),\n    labels = c(\"0%\", \"20%\", \"40%\", \"60%\", \"80%\", \"100%\")\n  )\n\n# show the plot\nscatter_plot_1\n\n\n\n\n\n\n\n\n\n# highlight point at (31.3, 39.4)\nhighlight_point_1 &lt;- data.frame(\n  homeownership = 31.3,\n  multi_unit = 39.4\n)\n\n# highlighting the point\nscatter_plot_1_hl &lt;- scatter_plot_1 +\n  \n  ## add highlight point circle\n  geom_point(data = highlight_point_1, aes(x = multi_unit, y = homeownership), color = \"red\", size = 3, shape = 1) +\n  \n  ## add both vertical and horizontal dash lines\n  geom_vline(xintercept = highlight_point_1$multi_unit, linetype = \"dashed\", color = \"red\") +\n  geom_hline(yintercept = highlight_point_1$homeownership, linetype = \"dashed\", color = \"red\")\n\n# show the plot\nscatter_plot_1_hl\n\n\n\n\n\n\n\n\n\n\n\n1.2 Figure 1.9: Scatter Plot\n# draw the scatter plot\nscatter_plot_2 &lt;- ggplot(county, aes(x = median_hh_income, y = pop_change)) +\n  \n  ## adjust the points\n  geom_point(color = \"steelblue\", fill = \"black\", shape = 21, stroke = 0.9) +\n  \n  ## add labels and graph title to make the graph readable\n  labs(\n    x = \"Median Household Income\",\n    y = \"Population Change Over 7 Years\",\n    title = \"Figure 1.9: Population Change vs. Median Household Income\"\n  ) +\n  \n  ## center the title text\n  theme(plot.title = element_text(hjust = 0.5)) +\n  \n  ## adjust the scale of x, y-axis\n  scale_x_continuous(\n    labels = c(\"$0K\", \"$20K\", \"$40K\", \"$60K\", \"$80K\", \"$100K\", \"$120K\"),\n    breaks = seq(0, 120000, by = 20000)\n  ) +\n  scale_y_continuous(\n    breaks = c(-10, 0, 10, 20),\n    labels = c(\"-10%\", \"0%\", \"10%\", \"20%\")\n  )\n\n# show the plot\nscatter_plot_2\n\n\n\n\n\n\n\n\n\n# highlight point at (22736, -3.63)\nhighlight_point_2 &lt;- data.frame(\n  median_hh_income = 22736,\n  pop_change = -3.63\n)\n\n# highlighting the point\nscatter_plot_2_hl &lt;- scatter_plot_2 +\n  \n  ## add highlight point circle\n  geom_point(data = highlight_point_2, aes(x = median_hh_income, y = pop_change), color = \"red\", size = 3, shape = 1) +\n  \n  ## add both vertical and horizontal dash lines\n  geom_vline(xintercept = highlight_point_2$median_hh_income, linetype = \"dashed\", color = \"red\") +\n  geom_hline(yintercept = highlight_point_2$pop_change, linetype = \"dashed\", color = \"red\")\n\n# show the plot\nscatter_plot_2_hl\n\n\n\n\n\n\n\n\n\n\n\n1.3 Figure 2.6: Histogram\nggplot(loan50, aes(x = interest_rate)) +\n  \n  ## plot the histogram (OPTIONAL: `boundary` specify the location of edge for each bin)\n  geom_histogram(binwidth = 2.5, fill = \"steelblue\", color = \"black\", boundary = 5) +\n  \n  ## other adjustments\n  labs(\n    x = \"Interest Rate\",\n    y = \"Frequency\",\n    title = \"Figure 2.6: A histogram of interest rate\"\n  ) +\n  scale_x_continuous(\n    labels = c(\"5%\", \"10%\", \"15%\", \"20%\", \"25%\"),\n    breaks = c(5, 10, 15, 20, 25)\n  ) +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\n\n\n1.4 Figure 2.10: Box Plot & Dot Plot\n# draw the graph by two different ways: box plot, and dot plot\nbox_dot_plot_raw &lt;- ggplot(loan50, aes(x = \"\", y = interest_rate)) +\n  \n  ## draw the box plot, dot plot, and overlap them together\n  geom_boxplot(width = 0.3) +\n  geom_dotplot(binaxis = 'y', stackdir = 'center', dotsize = 0.5, fill = \"lightblue\") +\n  \n  labs(\n    y = \"Interest Rate\",\n    title = \"Figure 2.10: Box plot and dot plot of interest rate\"\n  ) +\n  \n  ## adjust the scale and range of y-axis\n  scale_y_continuous(\n    labels = c(\"5%\", \"10%\", \"15%\", \"20%\", \"25%\"),\n    breaks = seq(5, 25, by = 5)\n  ) +\n  \n  ## adjust the graph title and x-axis title\n  theme(plot.title = element_text(hjust = 0.5))\n  \n# show the plot\nbox_dot_plot_raw\n\n\n\n\n\n\n\n\n\n\n1.4.1 (OPTIONAL) How to separate the box plot and dot plot beautifully?\nSince we haven’t introduced facet command, this should be leaved optional.\n# create two distinct dataset for dot/box graph, and append them together\n\n  ## data for dot plot\n  loan_data_plot_dot &lt;- loan50 %&gt;%\n    mutate(plot_type = \"Dot Plot\")\n\n  ## data for box plot\n  loan_data_plot_box &lt;- loan50 %&gt;%\n    mutate(plot_type = \"Box Plot\")\n\n  ## append together\n  loan_data_combined &lt;- bind_rows(loan_data_plot_dot, loan_data_plot_box)\n  \n# Draw two graphs separately with `facet` command\nbox_dot_plot &lt;- ggplot(loan_data_combined, aes(x = plot_type, y = interest_rate)) +\n  \n  ## dot plot and box plot\n  geom_dotplot(data = loan_data_combined %&gt;% filter(plot_type == \"Dot Plot\"), \n               binaxis = 'y', \n               stackdir = 'center', \n               dotsize = 0.5, \n               fill = \"lightblue\", \n               position = position_dodge(width = 0.4)\n              ) +\n  geom_boxplot(data = loan_data_combined %&gt;% filter(plot_type == \"Box Plot\"), \n               width = 0.3, \n               position = position_dodge(width = 0.9)\n              ) +\n  \n  ## other adjustments\n  labs(\n    y = \"Interest Rate\",\n    x = NULL,\n    title = NULL\n  ) +\n  scale_y_continuous(\n    labels = c(\"5%\", \"10%\", \"15%\", \"20%\", \"25%\"),\n    breaks = seq(5, 25, by = 5)\n  ) +\n  \n  theme(\n    axis.title.x = element_blank(),\n    plot.title = element_text(hjust = 0.5)\n  ) +\n  \n  ## (!!) utilize `facet_wrap` command to align the graphs by using variable \"plot_type\"\n  facet_wrap(~plot_type, scales = \"free_x\")\n\n# show the plot\nbox_dot_plot\n\n\n\n\n\n\n\n\n\n\n\n\n1.5 Figure 2.17: Contingency Table\ntable1 &lt;- table(loan$application_type, loan$homeownership, \n               dnn = c(\"app_type\", \"homeownership\"))\ntable1_withsum &lt;- addmargins(table1)\ntable1_withsum\n\n\n            homeownership\napp_type     MORTGAGE   OWN  RENT   Sum\n  individual     3839  1170  3496  8505\n  joint           950   183   362  1495\n  Sum            4789  1353  3858 10000\n\n\n\n\n1.6 Figure 2.18: Frequency Table\ntable2 &lt;- table(loan$homeownership)\ntable2_withsum &lt;- addmargins(table2)\ntable2_withsum\n\n\n\nMORTGAGE      OWN     RENT      Sum \n    4789     1353     3858    10000 \n\n\n\n\n1.7 Figure 2.23: Bar Graph\n# (OPTIONAL) adjust the order\nloan$application_type &lt;- fct_relevel(loan$application_type, \"joint\", \"individual\")\nloan$homeownership &lt;- fct_relevel(loan$homeownership, \"RENT\", \"MORTGAGE\", \"OWN\")\n\n# plot a: stacked bar\nggplot(loan, aes(x = homeownership, fill = application_type)) +\n  geom_bar() +\n  labs(\n    y = \"Frequency\",\n    fill = \"\"\n  ) +\n  scale_fill_manual(\n    values = c(\"individual\" = \"steelblue\", \"joint\" = \"gold\")\n  )\n\n\n\n\n\n\n\n\n\n# (OPTIONAL) adjust the order\nloan$application_type &lt;- fct_relevel(loan$application_type, \"individual\", \"joint\")\nloan$homeownership &lt;- fct_relevel(loan$homeownership, \"RENT\", \"MORTGAGE\", \"OWN\")\n\n# plot b: dodged bar\nggplot(loan, aes(x = homeownership, fill = application_type)) +\n  geom_bar(position = \"dodge\") +\n  labs(\n    y = \"Frequency\",\n    fill = \"\"\n  ) +\n  scale_fill_manual(\n    values = c(\"individual\" = \"steelblue\", \"joint\" = \"gold\")\n  )\n\n\n\n\n\n\n\n\n\n# (OPTIONAL) adjust the order\nloan$application_type &lt;- fct_relevel(loan$application_type, \"joint\", \"individual\")\nloan$homeownership &lt;- fct_relevel(loan$homeownership, \"RENT\", \"MORTGAGE\", \"OWN\")\n\n# plot c: standard stacked bar\nggplot(loan, aes(x = homeownership, fill = application_type)) +\n  geom_bar(position = \"fill\") +\n  labs(\n    y = \"Proportion\", \n    fill = \"\"\n  ) +\n  scale_fill_manual(values = c(\"individual\" = \"steelblue\", \"joint\" = \"gold\"))\n\n\n\n\n\n\n\n\n\ndata.frame(\n  mean = c(mean(loan$annual_income), mean(loan$total_credit_lines)),\n  median = c(median(loan$annual_income), median(loan$total_credit_lines)),\n  sd = c(sd(loan$annual_income), sd(loan$total_credit_lines)),\n  q25 = c(quantile(loan$annual_income, .25), quantile(loan$total_credit_lines, .25)),\n  q75 = c(quantile(loan$annual_income, .75), quantile(loan$total_credit_lines, .75)),\n  row.names = c(\"annual_income\", \"total_credit_line\")\n)\n\n\n1.8 Summary Statistics Table\n\n\n                        mean median          sd   q25   q75\nannual_income     79222.1484  65000 64734.29049 45000 95000\ntotal_credit_line    22.6796     21    11.88544    14    29",
    "crumbs": [
      "Homework Solutions",
      "Homework 1 Answers"
    ]
  },
  {
    "objectID": "homework/hw1_answer.html#textbook-exercise",
    "href": "homework/hw1_answer.html#textbook-exercise",
    "title": "Homework 1 Answers",
    "section": "2 Textbook Exercise",
    "text": "2 Textbook Exercise\n\n2.1 Question 1.4\n\nThe research question is: “Do asthmatic patients who practice the Buteyko method experience improvement in their condition?”\nThe cases are 600 adult patients aged 18–69 years diagnosed and currently treated for asthma.\nThe variables are whether or not the patient practiced the Buteyko method (categorical) and measures of quality of life, activity, asthma symptoms, and medication reduction of the patients (categorical, ordinal). It may also be reasonable to treat the ratings on a scale of 0 to 10 as discrete numerical variables.\n\n\n\n2.2 Question 1.10\n\nEach row of the data matrix represents a participant in the survey.\nThere are 1,691 participants in the survey.\nThe table below lists the types of variables included in the study:\n\n\n\n\nVariable\nType\n\n\n\n\nsex\ncategorical\n\n\nage\nnumerical, continuous\n\n\nmaritalStatus\ncategorical\n\n\ngrossIncome\nordinal*\n\n\nsmoke\ncategorical\n\n\namtWeekends\nnumerical, discrete\n\n\namtWeekdays\nnumerical, discrete\n\n\n\n* Note that income is a continuous numerical variable, but in this survey, it is recorded as an ordinal variable.\n\n\n2.3 Question 1.22\n\nObservational.\n\nNo. Because the study is observational, we cannot infer causation.\n\nPossible confounders: caffeine intake and lack of sleep. Either could explain the observed association between stress and muscle cramps (e.g., students may cramp due to increased caffeine use or insufficient sleep).\n\n\n\n2.4 Question 1.34\n\nRandomized experiment. Sampling is stratified by age; treatment is assigned at random.\nTreatment: those assigned to exercise twice a week.\nControl: those instructed not to exercise.\nYes. The blocking variable is age group; randomization is carried out within each block.\nParticipants cannot realistically be blinded to whether they exercise. Blinding of outcome assessors is possible but not described. As written, the study is not blinded and could be subject to placebo/Hawthorne/observer effects.\nBecause of random assignment, a causal effect of exercise on the measured mental-health outcome can be inferred for the study participants (and, with blocking done well, within age groups). Generalization depends on how the stratified sample was obtained; if it’s a good probability sample of the target population of 18–55-year-olds, results generalize to that population. Otherwise, external validity is limited.\nPre-register outcomes, blinded-trials, ensure adequate sample size, record potential time-varying confounders.\n\n\n\n2.5 Question 1.38\n\nSimple random sampling: effective — gives every household equal probability of selection.\n\nStratified sampling: effective — neighborhoods are distinct; stratifying ensures sampling from each neighborhood.\n\nCluster sampling: not effective — sampling whole neighborhoods would miss households from some areas, and neighborhoods differ greatly.\n\nMulti-stage sampling: suffers from the same issue as (c).\n\nConvenience sampling: not effective — yields a biased sample (e.g., only nearby/similar neighborhoods; misses distant ones).\n\n\n\n2.6 Question 1.40\n\nExplanatory variable: percent of the population with a bachelor’s degree.\nResponse variable: per-capita income (in thousands).\n\nRelationship: strong positive linear association — as the bachelor’s-degree percent increases, per-capita income tends to increase. Few counties exceed 60% bachelor’s degree or $50k per-capita income.\n\nCausality: observational study; no causal claim. We can only say higher bachelor’s-degree share is associated with higher per-capita income.\n\n\n\n2.7 Question 2.12\nMedian is around 80. Because the distribution is left-skewed, the mean is expected to be slightly lower than the median.\n\n\n2.8 Question 2.22\n\nPercent identifying as conservatives\n372 / 910 ≈ 40.9%.\nPercent favoring “apply for citizenship”\n278 / 910 ≈ 30.6%.\nPercent who are conservatives and favor citizenship\n57 / 910 ≈ 6.3%.\nAmong each ideology, percent who favor citizenship\nConservatives: 57 / 372 ≈ 15.3%.\nModerates: 120 / 363 ≈ 33.1%.\nLiberals: 101 / 175 ≈ 57.7%.\nDo ideology and immigration views appear independent?\nNo. If independent, the percent favoring citizenship would be about the same across ideologies; the conditional percents differ widely (15%, 33%, 58%), indicating association.\n\n\n\n2.9 Question 2.30\n\nIf \\(\\dfrac{\\bar{x}}{\\mathrm{median}} = 1\\), then \\(\\bar{x}=\\mathrm{median}\\). This matches symmetric distributions.\n\nIf \\(\\dfrac{\\bar{x}}{\\mathrm{median}} &lt; 1\\), then \\(\\bar{x}&lt;\\mathrm{median}\\). This matches left-skewed distributions (lower values pull the mean down).\n\nIf \\(\\dfrac{\\bar{x}}{\\mathrm{median}} &gt; 1\\), then \\(\\bar{x}&gt;\\mathrm{median}\\). This matches right-skewed distributions (higher values pull the mean up).\n\n\n\n2.10 Question 2.34\n\nHistogram: overall shape (including bimodality) and density are apparent, while these are not visible in a box plot.\nBox plot: median, quartiles (IQR), and identification of outliers are explicit, while these are harder to read from the histogram.\nPlausibly two groups with systematically different times: men vs women.\nWomen’s finishing times are generally higher than men’s, with a larger median and typically greater spread (IQR). Men’s times are lower on average and a bit less variable.\nA downward trend over years and the changing gap between men and women. It highlights temporal patterns that a single histogram/box plot, which aggregates over time, cannot show.",
    "crumbs": [
      "Homework Solutions",
      "Homework 1 Answers"
    ]
  },
  {
    "objectID": "homework/hw3_answer.html",
    "href": "homework/hw3_answer.html",
    "title": "Homework 3 Answers",
    "section": "",
    "text": "If you find any typos or errors, please feel free to contact me via email at r13323002@ntu.edu.tw. I would appreciate it and will correct the solution to prevent any misunderstandings.\nFor some R commands marked with ‘OPTIONAL,’ you don’t need to learn them. You will be completely fine on the computer quiz even if you choose to ignore them.\nIf you’re having trouble understanding the code, don’t hesitate to ask me for help. I’ll do my best to assist you during office hours or after the TA session.",
    "crumbs": [
      "Homework Solutions",
      "Homework 3 Answers"
    ]
  },
  {
    "objectID": "homework/hw3_answer.html#computer-exercises",
    "href": "homework/hw3_answer.html#computer-exercises",
    "title": "Homework 3 Answers",
    "section": "1 Computer Exercises",
    "text": "1 Computer Exercises\n\n1.1 CLT Simulation with Uniform Distribution\n# 1. Define distribution parameters, draw size, and simulation size\nuniform_min &lt;- -2\nuniform_max &lt;- 2\ndraw_size &lt;- c(2, 5, 15, 30)\nsimulation_size &lt;- 200\n\n# 2. Define function to:\n# (1) draw uniform sample according to different draw size; \n# (2) compute sample mean and return the mean\nsample_mean_unif &lt;- function(n){\n  samples &lt;- runif(n, min = uniform_min, max = uniform_max)\n  mean &lt;- mean(samples)\n  return(mean)\n}\n\n# 3. Before simulation, create an empty DataFrame for storing the simulation result later\nresult &lt;- data.frame()\n\n# 4. Draw sample according to different draw sizes\nfor (n in draw_size){\n  \n  ## 4.1 Given the draw size, draw sample and compute mean for 200 times\n  simulated_sample_means &lt;- replicate(simulation_size, sample_mean_unif(n))\n  \n  ## 4.2 Store the sample means in temporary DataFrame `df`\n  ##     `df` is a 200 x 2 DataFrame. Check it by yourself\n  df &lt;- data.frame(\n    draw_size = n,\n    means = simulated_sample_means\n  )\n  \n  ## 4.3 We store the simulation result by appending the sample means `df` to `result`\n  ##     so 'result' now should have 200+200+200+200 = 800 rows. Check it by yourself\n  result &lt;- rbind(result, df)\n  \n}\n\n# 5. Draw histogram\nggplot(data = result, aes(x = means)) +\n  geom_histogram(binwidth = 0.1, fill = \"steelblue\", color = \"gray\", alpha = 0.8, boundary = 0.1) +\n  facet_wrap(~draw_size) +\n  labs(\n    x = \"Simulated Sample Mean\",\n    y = \"Simulation ount\",\n    title = paste0(\"Histogram of Uniform Sample Mean under Diffrent Sample Size for 200 Simulations.\")\n  ) +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nNote that the mean of these histogram are all zero. Besides, as the size of draws increases, the sample variation decreases since the histogram became more centered.\n\n\n1.2 CLT Simulation with Exponential Distribution\n# 1. Define distribution parameters, draw size, and simulation size\nlambda &lt;- 1.5\ndraw_size &lt;- c(2, 5, 15, 30)\nsimulation_size &lt;- 200\n\n# 2. Define function to:\n# (1) draw exponential sample according to different draw size; \n# (2) compute sample mean and return the mean\nsample_mean_exp &lt;- function(n){\n  samples &lt;- rexp(n, rate = lambda)\n  mean &lt;- mean(samples)\n  return(mean)\n}\n\n# 3. Before simulation, create an empty DataFrame for storing the simulation result later\nresult &lt;- data.frame()\n\n# 4. draw sample according to different draw sizes\nfor (n in draw_size){\n  \n  ## 4.1 Given the draw size, draw sample and compute mean for 200 times\n  simulated_sample_means &lt;- replicate(simulation_size, sample_mean_exp(n))\n  \n  ## 4.2 Store the sample means in temporary DataFrame `df`\n  ##     `df` is a 200 x 2 DataFrame. Check it by yourself\n  df &lt;- data.frame(\n    draw_size = n,\n    means = simulated_sample_means\n  )\n  \n  ## 4.3 We store the simulation result by appending the sample means `df` to `result`\n  ##     so 'result' now should have 200+200+200+200 = 800 rows. Check it by yourself\n  result &lt;- rbind(result, df)\n  \n}\n\n# 5. Draw histogram\nggplot(data = result, aes(x = means)) +\n  geom_histogram(binwidth = 0.1, fill = \"steelblue\", color = \"gray\", alpha = 0.8, boundary = 0.1) +\n  facet_wrap(~draw_size) +\n  labs(\n    x = \"Simulated Sample Mean\",\n    y = \"Simulation ount\",\n    title = paste0(\"Histogram of Exponential Sample Mean under Diffrent Sample Size for 200 Simulations.\")\n  ) +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nNote that the mean of these histogram are all 1/1.5. Besides, as the size of draws increases, the sample variation decreases since the histogram became more centered.",
    "crumbs": [
      "Homework Solutions",
      "Homework 3 Answers"
    ]
  },
  {
    "objectID": "homework/hw3_answer.html#textbook-exercise",
    "href": "homework/hw3_answer.html#textbook-exercise",
    "title": "Homework 3 Answers",
    "section": "2 Textbook Exercise",
    "text": "2 Textbook Exercise\n\n2.1 Question 5.8\nRecall that the general formula is point estimate \\(\\pm z^* \\times \\text{SE}\\).\nFirst, identify the three values. The point estimate is 52%, \\(z^* = 2.58\\) for a 99% confidence level, and \\(\\text{SE} = 2.4\\).\n\\[\n52\\% \\;\\pm\\; 2.58 \\times 2.4\\% \\;\\;\\longrightarrow\\;\\; (45.8\\%,\\, 58.2\\%).\n\\]\nWe are 99% confident that 45.8% to 58.2% of U.S. adult Twitter users get some news on Twitter.\n\n\n2.2 Question 5.10\n\nFalse. 50% is included in the 99% confidence interval, hence a null hypothesis of \\(p = 0.50\\) would not be rejected at this level.\nFalse. The standard error measures the variability of the sample proportion and is unrelated to the proportion of the population included in the study.\nFalse. We need to increase the sample size to decrease the standard error.\nFalse. As the confidence level decreases, so does the margin of error, and hence the width of the confidence interval.\n\n\n\n2.3 Question 5.18\nFirst, the hypotheses should be about the population proportion (\\(p\\)), not the sample proportion.\nSecond, the null value should be what we are testing (0.25), not the observed value (0.24).\nThe correct way to set up these hypotheses is:\n\\[\n\\begin{cases}\nH_0: p = 0.25 \\\\\nH_A: p \\ne 0.25\n\\end{cases}\n\\]\n\n\n2.4 Question 5.26\n\nScenario I is higher. A sample mean based on less data tends to be less accurate and has a larger standard error.\nScenario I is higher. A higher confidence level \\(\\Rightarrow\\) a larger margin of error.\nThey are equal. For a given \\(Z\\)-score the p-value depends only on the \\(Z\\) value, not on the sample size.\nScenario I is higher. If the null is harder to reject (smaller \\(\\alpha\\)), we are more likely to make a Type II error when the alternative is true.\n\n\n\n\n2.5 Question 5.32\nPrepare — Hypotheses\n\\[\n\\begin{cases}\nH_0: p = 0.08,\\\\\nH_A: p \\ne 0.08 .\n\\end{cases}\n\\]\nUse significance level \\(\\alpha = 0.05\\).\nCheck\nSimple random sample \\(\\Rightarrow\\) independence.\nSuccess–failure condition: \\(21 \\ge 10\\) and \\(194-21=173 \\ge 10\\).\nCalculate\n\\[\n\\hat p = \\frac{21}{194} = 0.108\n\\]\n\\[\nSE = \\sqrt{\\frac{0.08(1-0.08)}{194}} = 0.0195\n\\]\n\\[\nZ=\\frac{0.108-0.08}{0.0195}=1.44\n\\]\nA one–tail area is about \\(0.075\\), so the two–sided p-value is \\(2\\times0.075 \\approx 0.15\\).\nConclude\nBecause the p-value (\\(0.15\\)) is greater than \\(\\alpha=0.05\\), we do not reject \\(H_0\\).\nThere is not convincing evidence that the fraction of children who are nearsighted differs from \\(0.08\\).\n\n\n\n2.6 Question 5.36\nAs the sample size increases, the standard error decreases.\nFor the same true effect, the test statistic (e.g., \\(Z\\)) increases, and the p-value decreases.",
    "crumbs": [
      "Homework Solutions",
      "Homework 3 Answers"
    ]
  },
  {
    "objectID": "homework/hw5_answer.html",
    "href": "homework/hw5_answer.html",
    "title": "Homework 5 Answers",
    "section": "",
    "text": "If you find any typos or errors, please feel free to contact me via email at r13323002@ntu.edu.tw. I would appreciate it and will correct the solution to prevent any misunderstandings.\nFor some R commands marked with ‘OPTIONAL,’ you don’t need to learn them. You will be completely fine on the computer quiz even if you choose to ignore them.\nIf you’re having trouble understanding the code, don’t hesitate to ask me for help. I’ll do my best to assist you during office hours or after the TA session.",
    "crumbs": [
      "Homework Solutions",
      "Homework 5 Answers"
    ]
  },
  {
    "objectID": "homework/hw5_answer.html#computer-exercises",
    "href": "homework/hw5_answer.html#computer-exercises",
    "title": "Homework 5 Answers",
    "section": "1 Computer Exercises",
    "text": "1 Computer Exercises\n\n1.1 Summary Table & Histogram\n# clean data: drop samples with unknown education degree, or unknown childcare hours\nchina_clean &lt;- china %&gt;% \n   filter(edu != 9 & is.na(edu) == FALSE) %&gt;% \n   filter(child_care != -99 & is.na(child_care) == FALSE)\n  \n# summary statistics table\nchina_clean %&gt;% summarize(\n    count = n(),\n    mean = mean(child_care),\n    sd = sd(child_care),\n    min = min(child_care),\n    max = max(child_care)\n  )\n# plot a histogram for `child_care`\nggplot(china_clean, aes(x = child_care)) +\n  \n  ## select an appropriate bin width\n  geom_histogram(binwidth = 10, fill = \"steelblue\", color = \"gray\") +\n  \n  ## add label and graph title to make the graph more readable\n  labs(\n    title = \"Histogram of Child Care Hours\",\n    x = \"Child Care Hours\",\n    y = \"Frequency\"\n  ) +\n  \n  ## center the graph title\n  theme(plot.title = element_text(hjust = 0.5))\nx(child_care)\n  )\n\n# clean data: drop samples with unknown education degree, or unknown childcare hours\nchina_clean &lt;- china %&gt;% \n   filter(edu != 9 & is.na(edu) == FALSE) %&gt;% \n   filter(child_care != -99 & is.na(child_care) == FALSE)\n  \n# summary statistics table\nchina_clean %&gt;% summarize(\n    count = n(),\n    mean = mean(child_care),\n    sd = sd(child_care),\n    min = min(child_care),\n    max = max(child_care)\n  )\n\n  count     mean      sd min max\n1   799 25.01001 28.6975   1 168\n\n#| echo: false        # hide code if this is the Answers page\n\n# plot a histogram for `child_care`\nggplot(china_clean, aes(x = child_care)) +\n  \n  ## select an appropriate bin width\n  geom_histogram(binwidth = 10, fill = \"steelblue\", color = \"gray\") +\n  \n  ## add label and graph title to make the graph more readable\n  labs(\n    title = \"Histogram of Child Care Hours\",\n    x = \"Child Care Hours\",\n    y = \"Frequency\"\n  ) +\n  \n  ## center the graph title\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\n\n1.2 Summary Table & Histogram: By Parent’s Gender\n# summary statistics table: by parent's gender\nchina_clean %&gt;%\n  group_by(gender) %&gt;%\n  summarize(\n    count = n(),\n    mean = mean(child_care),\n    sd = sd(child_care),\n    min = min(child_care),\n    max = max(child_care)\n  )\n# plot a histogram for `child_care`: by parent's gender\nggplot(china_clean, aes(x = child_care)) +\n  \n  ## select an appropriate bin width\n  geom_histogram(binwidth = 5, color = \"gray\", fill = \"steelblue\") +\n  \n  ## split the sample by parent's gender, set the nrow = 2 for comparison\n  facet_wrap(~gender, nrow = 2) +\n  \n  ## add label and graph title to make the graph more readable\n  labs(\n    title = \"Histogram of Child Care Hours: by Parent's Gender\",\n    x = \"Child Care Hours\",\n    y = \"Frequency\",\n    fill = \"Gender\"\n  ) +\n  \n  ## center the graph title\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n# A tibble: 2 × 6\n  gender count  mean    sd   min   max\n   &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt;\n1      1   312  15.7  20.7     1   168\n2      2   487  31.0  31.4     1   168\n\n\n\n\n\n\n\n\n\n\n\n1.3 Hypothesis Testing (Child Care and Parent’s Gender)\n# t-test\nt_test_result &lt;- t.test(child_care ~ gender, data = china_clean)\nprint(t_test_result)\n\n\n\n    Welch Two Sample t-test\n\ndata:  child_care by gender\nt = -8.2549, df = 796.45, p-value = 6.291e-16\nalternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n95 percent confidence interval:\n -18.83770 -11.59989\nsample estimates:\nmean in group 1 mean in group 2 \n       15.73397        30.95277 \n\n\nSet \\(\\alpha=0.05\\). The absolute value of the t-statistic (-8.25) is greater than the critical value of 1.96. Besides, the p-value is less than 0.05. So we reject \\(H_0\\), implying the average childcare hours is significantly different between males and females.\n\n\n1.4 Summary Table & Box Plot: By Parent’s Education Level\n# summary statistics table: by parent's education level\nchina_clean %&gt;%\n    group_by(edu) %&gt;%\n    summarise(\n      count = n(),\n      mean = mean(child_care),\n      sd = sd(child_care),\n      min = min(child_care),\n      max = max(child_care)\n    )\n# plot side-by-side box plots for `child_care`: by parent's educational level\nggplot(china_clean, aes(y = child_care)) +\n  \n  ## remove the scale of x-axis\n  geom_boxplot(aes(x = \"\")) +\n  \n  ## split the sample by education level, set nrow = 1 for comparison\n  facet_wrap(~edu, nrow = 1) +\n  \n  ## add label and graph title to make the graph more readable\n  labs(\n    title = \"Box Plot of Child Care Hours: by Parent's Education Level\",\n    x = \"Education Level\",\n    y = \"Child Care Hours\"\n  ) +\n  \n  ## center the graph title\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n# A tibble: 5 × 6\n    edu count  mean    sd   min   max\n  &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt;\n1     1   223  25.4  30.0     1   168\n2     2   351  24.7  27.6     1   168\n3     3    80  22.2  28.8     1   161\n4     4    78  30.9  33.4     1   140\n5     5    67  21.8  23.3     1   108\n\n\n\n\n\n\n\n\n\n\n\n1.5 Hypothesis Testing (Child Care and Parent’s Education Level)\n# summary statistics table: by parent's education level\nanova_result &lt;- aov(child_care ~ as.factor(edu), data = china_clean)\nprint(anova_result)\nsummary(anova_result)\n\n\nCall:\n   aov(formula = child_care ~ as.factor(edu), data = china_clean)\n\nTerms:\n                as.factor(edu) Residuals\nSum of Squares          4142.1  653047.8\nDeg. of Freedom              4       794\n\nResidual standard error: 28.67888\nEstimated effects may be unbalanced\n\n\n                Df Sum Sq Mean Sq F value Pr(&gt;F)\nas.factor(edu)   4   4142  1035.5   1.259  0.285\nResiduals      794 653048   822.5               \n\n\nSet \\(\\alpha=0.05\\). The F-statistics (1.259) is less than the critical value of \\(X\\). Besides, the p-value (0.285) is greater than 0.05. Thus, we do not reject \\(H_0\\). We don’t have strong evidence that the average childcare hours vary with parents’ education.",
    "crumbs": [
      "Homework Solutions",
      "Homework 5 Answers"
    ]
  },
  {
    "objectID": "homework/hw5_answer.html#textbook-exercise",
    "href": "homework/hw5_answer.html#textbook-exercise",
    "title": "Homework 5 Answers",
    "section": "2 Textbook Exercise",
    "text": "2 Textbook Exercise\n\n2.1 Question 7.4\n\nWe have \\(n = 26\\), \\(T = 2.485\\), \\(df = 26 - 1 = 25\\), and \\(p\\text{-value} = 0.020\\). Do not reject \\(H_0\\).\nWe have \\(n = 26\\), \\(T = 0.5\\), \\(df = 18 - 1 = 17\\), and \\(p\\text{-value} = 0.623\\). Do not reject \\(H_0\\).\n\n\n\n2.2 Question 7.12\n\n\\[\n\\begin{cases}\nH_0:\\ \\mu = 35,\\\\\nH_A:\\ \\mu \\neq 35\n\\end{cases}\n\\]\n\n\n\nIndependence: if we can assume that these 52 officers represent a random sample (big assumption), then independence would be satisfied, but we cannot check this.\nNormality: we don’t have a plot of the distribution that we can use to check this condition. We at least have more than 30 observations, so the distribution would have to be extremely skewed to be an issue. We again cannot check this, but this seems like a less concerning issue than the independence consideration.\n\n\nThe test statistic and the p-value can be calculated as follows:\n\n\\[\nT \\;=\\; \\frac{124.32 - 35}{\\dfrac{37.74}{\\sqrt{52}}} \\;\\approx\\; 17.17\n\\]\n\\[\ndf \\;=\\; 52 - 1 \\;=\\; 51\n\\]\n\\[\np\\text{-value} \\;=\\; 2 \\times P\\!\\left(T_{51} &gt; 17.07\\right) \\;&lt;\\; 0.001\n\\]\nThe hypothesis test yields a very small p-value, so we reject \\(H_0\\). Given the direction of the data, there is very convincing evidence that the police officers have been exposed to a higher concentration of lead than individuals living in a suburban area.\n\n\n2.3 Question 7.20\n\nThe median writing score is slightly higher but it’s difficult to tell if the average scores on the two tests are different or not.\nNo, the score of one student on the reading test is not independent of their score on the writing test.\nLet \\(\\text{diff} = \\text{read} - \\text{write}\\). Then the hypotheses are: \\[\n\\begin{cases}\nH_0:\\ \\mu_{\\text{diff}} = 0\\\\\nH_A:\\ \\mu_{\\text{diff}} \\ne 0\n\\end{cases}\n\\]\nThe conditions for the sampling distribution of \\(\\bar{x}_{\\text{diff}}\\) to be nearly normal and the estimate of the standard error to be sufficiently accurate are as follows:\n\n\nIndependence: Students are randomly sampled and \\(200 &lt; 10\\%\\) of all students who take this survey, therefore we can assume that the reading and writing scores of one student are independent of another.\n\nNormality: The distribution of the differences appears fairly symmetric, so we can assume that the sampling distribution of average differences will be approximately normal.\n\n\nThe test statistic and the p-value can be calculated as follows: \\[\nT\n= \\frac{\\bar{x}_{\\text{diff}} - \\mu_{\\text{diff}}}{s_{\\text{diff}}/\\sqrt{n}}\n= \\frac{-0.545 - 0}{\\dfrac{8.887}{\\sqrt{200}}}\n= \\frac{-0.545}{0.628}\n\\approx -0.87\n\\]\n\n\\[\ndf = 200 - 1 = 199\n\\]\n\\[\np\\text{-value} = P\\!\\left(\\lvert T_{199}\\rvert &gt; 0.87\\right) &gt; 0.2\n\\]\nSince the p-value \\(&gt; 0.05\\), fail to reject \\(H_0\\). The data do not provide convincing evidence of a difference between the average reading and writing scores.\n\nWe may have made a Type 2 error, i.e. we may have incorrectly failed to reject \\(H_0\\). In this context, a Type 2 error means deciding that the data do not provide convincing evidence of a difference between the average reading and writing scores of students when in reality there is a difference.\nSince we failed to reject \\(H_0\\), which claimed the average difference is equal to \\(0\\), we would expect a confidence interval to include this value.\n\n\n\n2.4 Question 7.28\nThe hypotheses are as follows: \\[\n\\begin{cases}\nH_0:\\ \\mu_{A,c} = \\mu_{M,c} \\\\\nH_A:\\ \\mu_{A,c} \\ne \\mu_{M,c}\n\\end{cases}\n\\]\nWe are told to assume that conditions for inference are satisfied. Then, the test statistic and the p-value can be calculated as follows: \\[\nT\n= \\frac{(\\bar{x}_{A,c}-\\bar{x}_{M,c})-(\\mu_{A,c}-\\mu_{M,c})}\n       {\\sqrt{\\dfrac{s_{A,c}^2}{n_{A,c}}+\\dfrac{s_{M,c}^2}{n_{M,c}}}}\n= \\frac{16.12-19.85-0}{\\sqrt{\\dfrac{3.58^2}{26}+\\dfrac{4.51^2}{26}}}\n= \\frac{-3.37}{1.13} \\approx -3.3\n\\]\n\\[\ndf=\\min(n_{M,c}-1,\\ n_{A,c}-1)=\\min(26-1,\\ 26-1)=25\n\\]\n\\[\np\\text{-value}=P\\!\\left(|T_{25}|&gt;3.3\\right) &lt; 0.01\n\\]\nSince p-value \\(&lt; 0.05\\), reject \\(H_0\\). The data provide strong evidence that there is a difference in the average city mileage between cars with automatic and manual transmissions.\n\n\n2.5 Question 7.30\n\\[\ndf=\\min(n_1-1,\\ n_2-1)=\\min(26-1,\\ 26-1)=25\n\\qquad\\Rightarrow\\qquad t^*_{25}=2.49\n\\]\n\\[\n(\\bar{x}_{A,\\text{hwy}}-\\bar{x}_{M,\\text{hwy}})\\ \\pm\\ t^*_{df}\n\\sqrt{\\dfrac{s_{A,\\text{hwy}}^2}{n_{A,\\text{hwy}}}+\\dfrac{s_{M,\\text{hwy}}^2}{n_{M,\\text{hwy}}}}\n= (22.92-27.88)\\ \\pm\\ 2.49\\times \\sqrt{\\dfrac{5.29^2}{26}+\\dfrac{5.01^2}{26}}\n\\]\n\\[\n= -4.96 \\ \\pm\\ 2.49\\times 1.43\n= -4.96 \\ \\pm\\ 3.56\n= (-8.52,\\ -1.4)\n\\]\nWe are 98% confident that on the highway cars with manual transmissions get on average 1.4 to 8.52 MPG more than cars with automatic transmissions.\n\n\n2.6 Question 7.34\nDifference we care about: 0.5. Single tail of 90%: \\(0.84 \\times SE\\). At the 5% significance level, the rejection region bounds span \\(\\pm 1.96 \\times SE\\).\n\\[\n0.5 = 0.84 \\times SE + 1.96 \\times SE = 2.8 \\times SE\n\\]\n\\[\nSE = 0.1786 \\;=\\; \\sqrt{\\frac{(2.2)^2}{n} + \\frac{(2.2)^2}{n}}\n\\]\n\\[\nn = 303.47\n\\]\nWe will need 304 plots of land for each fertilizer.\n\n\n2.7 Question 7.40\nThe conditions that need to be satisfied for ANOVA are:\n\nIndependence: We are not told if the students are randomly assigned to discussion sections, so we cannot be sure of independence of observations. That is, these data will not allow us to attribute any differences in scores to the teaching assistants since these data are observational. Students with different academic strengths may have tended to enroll in different sections.\nApproximately normal: We are not given plots of the distributions of grades by discussion section, therefore we cannot check this condition. Also, the sample sizes are not all large, so we can’t relax this condition.\nConstant variance: Based on the standard deviations given in the summary table, the constant variance assumption appears to be reasonable for most groups, but not all. Also, the sample sizes aren’t consistent so we can’t relax this condition.\n\nIn order to proceed with the test, we will need to assume independence and approximately normal distributions within groups.\nThe hypotheses are as follows:\n\\[\n\\begin{cases}\nH_0: \\mu_1 = \\mu_2 = \\cdots = \\mu_8, \\\\\nH_A: \\text{The average score varies across some (or all) groups.}\n\\end{cases}\n\\]\n\\[\nF_{7,198} = 1.87\n\\]\nWith a p-value \\(= 0.0767\\). With a p-value \\(&gt; 0.05\\), we fail to reject \\(H_0\\). The data do not provide convincing evidence that the average score varies across some (or all) groups.",
    "crumbs": [
      "Homework Solutions",
      "Homework 5 Answers"
    ]
  },
  {
    "objectID": "quiz/Quiz_1.html",
    "href": "quiz/Quiz_1.html",
    "title": "Quiz 1",
    "section": "",
    "text": "Open in new tab · Download PDF",
    "crumbs": [
      "Quizzes",
      "Quiz 1"
    ]
  },
  {
    "objectID": "quiz/Quiz_2.html",
    "href": "quiz/Quiz_2.html",
    "title": "Quiz 2",
    "section": "",
    "text": "Open in new tab · Download PDF",
    "crumbs": [
      "Quizzes",
      "Quiz 2"
    ]
  },
  {
    "objectID": "quiz/Quiz_3.html",
    "href": "quiz/Quiz_3.html",
    "title": "Quiz 3",
    "section": "",
    "text": "Open in new tab · Download PDF",
    "crumbs": [
      "Quizzes",
      "Quiz 3"
    ]
  },
  {
    "objectID": "quiz/Quiz_4.html",
    "href": "quiz/Quiz_4.html",
    "title": "Quiz 4",
    "section": "",
    "text": "Open in new tab · Download PDF",
    "crumbs": [
      "Quizzes",
      "Quiz 4"
    ]
  },
  {
    "objectID": "quiz/Quiz_5.html",
    "href": "quiz/Quiz_5.html",
    "title": "Quiz 5",
    "section": "",
    "text": "Open in new tab · Download PDF",
    "crumbs": [
      "Quizzes",
      "Quiz 5"
    ]
  }
]